{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_y-T9UF9wpc",
        "outputId": "f7a8454b-7441-4f78-ecd5-9850cfa738e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting underthesea\n",
            "  Downloading underthesea-6.8.4-py3-none-any.whl (20.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea) (8.1.7)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea) (6.0.1)\n",
            "Collecting underthesea-core==1.0.4 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->underthesea) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2024.6.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (3.5.0)\n",
            "Installing collected packages: underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.10 underthesea-6.8.4 underthesea-core-1.0.4\n"
          ]
        }
      ],
      "source": [
        "pip install underthesea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj2v6oKkJlcR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from underthesea import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahiia4dHP6Y0"
      },
      "source": [
        "# Mục mới"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2jsndf23y3L"
      },
      "outputs": [],
      "source": [
        "def load_all_data(data_path):\n",
        "    all_data = []\n",
        "    for filename in os.listdir(data_path):\n",
        "        if filename.endswith('.json'):\n",
        "            file_path = os.path.join(data_path, filename)\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "                all_data.extend(data['data'])\n",
        "    return {'data': all_data}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkVGeltL31R3"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cySWbxOM6IwS"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data):\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    for article in data['data']:\n",
        "        for paragraph in article['paragraphs']:\n",
        "            context = clean_text(paragraph['context'])\n",
        "            for qa in paragraph['qas']:\n",
        "                question = clean_text(qa['question'])\n",
        "                is_impossible = qa.get('is_impossible', False)  #Do ngữ liệu nhiều chỗ define thiếu is_impossible nên sẽ mặc định là False\n",
        "                if not is_impossible:\n",
        "                    for answer in qa['answers']:\n",
        "                        answer_text = clean_text(answer['text'])\n",
        "                        answer_start = answer['answer_start']\n",
        "                        contexts.append(context)\n",
        "                        questions.append(question)\n",
        "                        answers.append({\n",
        "                            'text': answer_text,\n",
        "                            'start': answer_start\n",
        "                        })\n",
        "    return contexts, questions, answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMIsG5kOKBRH"
      },
      "outputs": [],
      "source": [
        "def tokenize_texts(texts):\n",
        " return [word_tokenize(text, format=\"text\") for text in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyBQdxTZKDur"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/data'\n",
        "squad_data = load_all_data(data_path)\n",
        "contexts, questions, answers = preprocess_data(squad_data)\n",
        "tokenized_contexts = tokenize_texts(contexts)\n",
        "tokenized_questions = tokenize_texts(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07Z3kZutCtMg"
      },
      "outputs": [],
      "source": [
        "tokenized_questions[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XsvYGi49-Kq",
        "outputId": "8754bf8c-7e76-44b9-8aa4-7796d453ba96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
          ]
        }
      ],
      "source": [
        "pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MCniQGRRK93"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yixwI9H4LVj"
      },
      "outputs": [],
      "source": [
        "# Tokenize ngữ liệu\n",
        "split_context_pre_train = [context.split() for context in tokenized_contexts]\n",
        "split_question_pre_train = [question.split() for question in tokenized_questions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo7X2J8YkNGE"
      },
      "outputs": [],
      "source": [
        "split_question_pre_train[100:110]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r517mQU9kMZR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_FWej1tRTdZ"
      },
      "outputs": [],
      "source": [
        "# Tạo mô hình Word2Vec\n",
        "model_word2vec = Word2Vec(vector_size=100, window=10, min_count=1, sg=1, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEMfTd3LtvKj"
      },
      "outputs": [],
      "source": [
        "# Xây dựng từ điển\n",
        "model_word2vec.build_vocab(split_question_pre_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60ATl10yu3NT",
        "outputId": "e4d26d17-211e-4367-fffb-2b077fb0301b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1952236, 3667600)"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_word2vec.train(split_question_pre_train, total_examples=model_word2vec.corpus_count, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clbXlmB1RZEQ"
      },
      "outputs": [],
      "source": [
        "# Lưu mô hình Word2Vec đã huấn luyện\n",
        "model_word2vec.save(\"/content/word2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5KLEP8vuACC",
        "outputId": "5efd9214-a79a-4cab-dab1-94e9bec69d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('chấm_dứt', 0.5507318377494812), ('muốn', 0.5413239002227783), ('trở_thành', 0.5283077955245972), ('mới', 0.5205602049827576), ('báo', 0.5093007683753967)]\n"
          ]
        }
      ],
      "source": [
        "similarWord = model_word2vec.wv.most_similar('hợp_đồng', topn=5)\n",
        "print(similarWord)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44KFa635Quug",
        "outputId": "dc1a5d3a-c6c9-4d59-ed61-f134043191f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.25.2)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLtaWHu6QamW"
      },
      "outputs": [],
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# Tạo BM25 model\n",
        "bm25 = BM25Okapi(split_question_pre_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbJ89GUERWeJ",
        "outputId": "0b0c5a35-0917-451b-d9b1-d7b2697dda8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['hợp_đồng lao_động']\n"
          ]
        }
      ],
      "source": [
        "questionBm25 = \"hợp đồng lao động\"\n",
        "tokenized_query = tokenize_texts([questionBm25])\n",
        "print(tokenized_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWdSo9NhRbyT",
        "outputId": "ba65e002-b5f1-4ca7-f791-0e0a5ab50ce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# Tính điểm số BM25\n",
        "\n",
        "bm25_scores = bm25.get_scores(tokenized_query)\n",
        "print(bm25_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NakdIXGUReaT",
        "outputId": "e7ad4828-6769-44e5-c8a9-5eb9097a3404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Câu hỏi người dùng: bảo hiểm y tế\n",
            "Các câu hỏi có điểm số cao nhất:\n",
            "Điểm số: 0.0000 - Câu hỏi: ['người', 'sử_dụng', 'lao_động', 'có', 'nghĩa_vụ', 'gì', 'nếu', 'tranh_chấp', 'lao_động', 'phát_sinh', 'sau', 'thời_gian', 'thử', 'việc']\n",
            "Điểm số: 0.0000 - Câu hỏi: ['người', 'sử_dụng', 'lao_động', 'phải', 'giải_quyết', 'các', 'tranh_chấp', 'phát_sinh', 'trong', 'quá_trình', 'thực_hiện', 'thỏa_ước', 'lao_động', 'tập_thể', 'theo', 'điều', 'gì']\n",
            "Điểm số: 0.0000 - Câu hỏi: ['tổ_chức', 'đại_diện', 'người', 'lao_động', 'có', 'trách_nhiệm', 'gì', 'trong', 'việc', 'giải_quyết', 'tranh_chấp', 'lao_động', 'tập_thể']\n",
            "Điểm số: 0.0000 - Câu hỏi: ['người', 'sử_dụng', 'lao_động', 'phải', 'tuân_thủ', 'các', 'quy_định', 'của', 'pháp_luật', 'về', 'điều', 'gì']\n",
            "Điểm số: 0.0000 - Câu hỏi: ['người', 'sử_dụng', 'lao_động', 'có', 'nghĩa_vụ', 'gì', 'trong', 'việc', 'giải_quyết', 'tranh_chấp', 'lao_động', 'tập_thể']\n",
            "Điểm số: 0.0000 - Câu hỏi: ['người', 'lao_động', 'có_thể', 'yêu_cầu', 'ai', 'giải_quyết', 'tranh_chấp', 'lao_động', 'tập_thể', 'theo', 'quy_định', 'của', 'pháp_luật']\n",
            "Điểm số: 0.0000 - Câu hỏi: ['người', 'lao_động', 'có', 'quyền', 'yêu_cầu', 'gì', 'trong', 'việc', 'giải_quyết', 'tranh_chấp', 'lao_động', 'tập_thể']\n",
            "Điểm số: 0.0000 - Câu hỏi: ['cơ_quan', 'nhà_nước', 'có', 'trách_nhiệm', 'gì', 'trong', 'quá_trình', 'giải_quyết', 'tranh_chấp', 'lao_động']\n",
            "Điểm số: 0.0000 - Câu hỏi: ['cơ_quan', 'nhà_nước', 'có', 'thẩm_quyền', 'có', 'trách_nhiệm', 'gì', 'trong', 'việc', 'giải_quyết', 'tranh_chấp', 'lao_động']\n",
            "Điểm số: 0.0000 - Câu hỏi: ['các', 'bên', 'có', 'nghĩa_vụ', 'gì', 'về', 'việc', 'giải_quyết', 'tranh_chấp', 'lao_động']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Xếp hạng các câu hỏi dựa trên điểm số\n",
        "top_n = np.argsort(bm25_scores)[::-1][:10]\n",
        "\n",
        "# Hiển thị các câu hỏi có điểm số cao nhất\n",
        "print(\"Câu hỏi người dùng:\", questionBm25)\n",
        "print(\"Các câu hỏi có điểm số cao nhất:\")\n",
        "for index in top_n:\n",
        "    print(f\"Điểm số: {bm25_scores[index]:.4f} - Câu hỏi: {split_question_pre_train[index]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "6zsrbeG560Kv"
      },
      "outputs": [],
      "source": [
        "# Changed\n",
        "def get_avg_word2vec_vector(user_question):\n",
        "    words = user_question\n",
        "    word_vectors = [model_word2vec.wv[word] for word in words if word in model_word2vec.wv]\n",
        "    if not word_vectors:\n",
        "        return np.zeros(model_word2vec.vector_size)\n",
        "    return np.mean(word_vectors, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "XV6GheqSOXfG"
      },
      "outputs": [],
      "source": [
        "# Changed\n",
        "\n",
        "def get_word2vec_scores(user_question, questions):\n",
        "    query_vector = get_avg_word2vec_vector(user_question)\n",
        "    scores = []\n",
        "    for question in questions:\n",
        "        question_vector = get_avg_word2vec_vector(simple_preprocess(question))\n",
        "        score = np.dot(query_vector, question_vector)\n",
        "        if np.isnan(score):\n",
        "            score = 0\n",
        "        scores.append(score)\n",
        "    return np.array(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "XjbjPE39-a22"
      },
      "outputs": [],
      "source": [
        "# Added\n",
        "def get_bm25_scores(user_question):\n",
        "    bm_25_score = bm25.get_scores(user_question)\n",
        "    scores = (bm_25_score - np.min(bm_25_score)) / (np.max(bm_25_score) - np.min(bm_25_score))\n",
        "    # Thay thế giá trị nan bằng 0\n",
        "    scores = np.nan_to_num(scores)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "Q8nB6tja-iTd"
      },
      "outputs": [],
      "source": [
        "# Added\n",
        "def get_combined_scores(user_question, questions):\n",
        "    tokenized_query = simple_preprocess(tokenize_texts([user_question])[0])\n",
        "    word2vec_scores = get_word2vec_scores(tokenized_query, questions)\n",
        "    bm25_scores = get_bm25_scores(tokenized_query)\n",
        "    word2vec_scores = (word2vec_scores - np.min(word2vec_scores)) / (np.max(word2vec_scores) - np.min(word2vec_scores))\n",
        "    combined_scores = word2vec_scores + bm25_scores\n",
        "    # Thay thế giá trị nan bằng 0 trong combined_scores\n",
        "    combined_scores = np.nan_to_num(combined_scores)\n",
        "    return combined_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "YJlhxQ0V-6z8"
      },
      "outputs": [],
      "source": [
        "def find_best_matching_question(user_question, questions):\n",
        "    combined_scores = get_combined_scores(user_question, questions)\n",
        "    if np.all(combined_scores == 0):\n",
        "        return \"Không có câu hỏi được tìm thấy\"\n",
        "    best_match_idx = np.argmax(combined_scores)\n",
        "    return questions[best_match_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cx-YF6s_ATm",
        "outputId": "f6b9df89-8e58-4e23-84ed-795c77ca80c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Question: Người lao động tham gia mấy loại bảo hiểm nào\n",
            "Best matching question: người sử dụng lao động phải tham gia loại bảo hiểm nào cho lao động đặc thù theo quy định của pháp luật\n"
          ]
        }
      ],
      "source": [
        "input_question = \"Người lao động tham gia mấy loại bảo hiểm nào\"\n",
        "best_question = find_best_matching_question(input_question, questions)\n",
        "\n",
        "print(f\"User Question: {input_question}\")\n",
        "print(f\"Best matching question: {best_question}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}