{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwQwex2XqQyf",
        "outputId": "600673df-24a5-4cdf-a997-20a0e5418b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=93fab41baa49785e2a8fd02a0c009aa469fd3710fcaf46cc278c92a14437211b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: xxhash, requests, pyarrow, dill, rouge_score, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 rouge_score-0.1.2 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install datasets rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnWjdXbskRW2",
        "outputId": "dd2cc19c-eeef-4021-ad90-8467ff5c1cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvITVD2eqXoL"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from transformers import RobertaTokenizerFast, DefaultDataCollator, TrainingArguments, Trainer, AutoModelForQuestionAnswering\n",
        "from datasets import Dataset\n",
        "import json\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38pRYAo6Qc4c",
        "outputId": "f5f8db54-cecf-406b-a21c-ded7f84673a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMeWNHiAqlYm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def update_answer_starts_and_filter(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    updated_data = {\"version\": data.get(\"version\", \"\"), \"data\": []}\n",
        "\n",
        "    for article in data['data']:\n",
        "        updated_article = {\"title\": article.get(\"title\", \"\"), \"paragraphs\": []}\n",
        "\n",
        "        for paragraph in article['paragraphs']:\n",
        "            context = paragraph['context']\n",
        "            updated_paragraph = {\"context\": context, \"qas\": []}\n",
        "\n",
        "            for qa in paragraph['qas']:\n",
        "                updated_qa = {\"question\": qa['question'], \"id\": qa['id'], \"answers\": []}\n",
        "\n",
        "                for answer in qa['answers']:\n",
        "                    answer_text = answer['text']\n",
        "                    answer_start = context.find(answer_text)\n",
        "                    if answer_start != -1:\n",
        "                        updated_qa['answers'].append({\"text\": answer_text, \"answer_start\": answer_start})\n",
        "\n",
        "                if updated_qa['answers']:\n",
        "                    updated_paragraph['qas'].append(updated_qa)\n",
        "\n",
        "            if updated_paragraph['qas']:\n",
        "                updated_article['paragraphs'].append(updated_paragraph)\n",
        "\n",
        "        if updated_article['paragraphs']:\n",
        "            updated_data['data'].append(updated_article)\n",
        "\n",
        "    return updated_data\n",
        "\n",
        "def save_updated_data(data, output_file_path):\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "input_file_path = '/content/drive/MyDrive/model_giaoduc/datagd.json'\n",
        "output_file_path = '/content/drive/MyDrive/model_giaoduc/updateDataGd.json'\n",
        "\n",
        "updated_data = update_answer_starts_and_filter(input_file_path)\n",
        "save_updated_data(updated_data, output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdN_-URaHP1j"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Đọc dữ liệu từ file JSON\n",
        "with open('/content/drive/MyDrive/model_giaoduc/updateDataGd.json', 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "contexts = []\n",
        "questions = []\n",
        "answers = []\n",
        "for article in data['data']:\n",
        "    for paragraph in article['paragraphs']:\n",
        "        context = paragraph['context']\n",
        "        for qa in paragraph['qas']:\n",
        "            question = qa['question']\n",
        "            answer = qa['answers'][0]['text'] if qa['answers'] else None\n",
        "            answer_start = context.find(answer) if answer else None\n",
        "            if answer:\n",
        "                contexts.append(context)\n",
        "                questions.append(question)\n",
        "                answers.append({\n",
        "                    \"text\": [answer],\n",
        "                    \"start\": [answer_start]\n",
        "                })\n",
        "\n",
        "# Chuyển dữ liệu thành định dạng list of tuples\n",
        "data = list(zip(contexts, questions, answers))\n",
        "\n",
        "# Chia dữ liệu thành train và val (80% train, 20% temp)\n",
        "train_data, val_data = train_test_split(data, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Chuyển đổi dữ liệu trở lại thành các dictionary để lưu vào file JSON\n",
        "def convert_to_dict(data):\n",
        "    contexts, questions, answers = zip(*data)\n",
        "    return {\n",
        "        'context': list(contexts),\n",
        "        'question': list(questions),\n",
        "        'answer': list(answers)\n",
        "    }\n",
        "\n",
        "train_dict = convert_to_dict(train_data)\n",
        "val_dict = convert_to_dict(val_data)\n",
        "\n",
        "# Lưu dữ liệu vào các file JSON\n",
        "with open('train_data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(train_dict, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "with open('val_data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(val_dict, f, ensure_ascii=False, indent=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_and_preprocess_squad(input_file, tokenizer, max_length=258):\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    for article in data['data']:\n",
        "        for paragraph in article['paragraphs']:\n",
        "            context = paragraph['context']\n",
        "            for qa in paragraph['qas']:\n",
        "                question = qa['question']\n",
        "                answer = qa['answers'][0]['text'] if qa['answers'] else None\n",
        "                answer_start = qa['answers'][0]['answer_start'] if qa['answers'] else None\n",
        "                if answer:\n",
        "                    # Xử lý trường hợp context lớn hơn max_length\n",
        "                    if len(tokenizer.encode(context)) > max_length:\n",
        "                        start_pos = max(0, answer_start - max_length // 2)\n",
        "                        end_pos = min(len(context), start_pos + max_length)\n",
        "                        context = context[start_pos:end_pos]\n",
        "                        answer_start = context.find(answer)\n",
        "\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    if not isinstance(answer_start, (int, float)):\n",
        "                        answer_start = 0\n",
        "                    answers.append({\n",
        "                        \"text\": [answer.lower()],\n",
        "                        \"start\": [answer_start]\n",
        "                    })\n",
        "\n",
        "    # Kiểm tra độ dài của các cột\n",
        "    assert len(contexts) == len(questions) == len(answers)\n",
        "\n",
        "    # Tạo từ điển dữ liệu\n",
        "    dataset = {\n",
        "        'context': contexts,\n",
        "        'question': questions,\n",
        "        'answer': answers\n",
        "    }\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def split_data(dataset, test_size=0.1):\n",
        "    contexts = dataset['context']\n",
        "    questions = dataset['question']\n",
        "    answers = dataset['answer']\n",
        "\n",
        "    train_contexts, val_contexts, train_questions, val_questions, train_answers, val_answers = train_test_split(\n",
        "        contexts, questions, answers, test_size=test_size, random_state=42\n",
        "    )\n",
        "\n",
        "    train_dataset = {\n",
        "        'context': train_contexts,\n",
        "        'question': train_questions,\n",
        "        'answer': train_answers\n",
        "    }\n",
        "\n",
        "    val_dataset = {\n",
        "        'context': val_contexts,\n",
        "        'question': val_questions,\n",
        "        'answer': val_answers\n",
        "    }\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q4P67bwKfUSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = '/content/drive/MyDrive/model_giaoduc/updateDataGd.json'\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('vinai/phobert-base')\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"vinai/phobert-base\")\n",
        "model.train()\n",
        "\n",
        "dataset = load_and_preprocess_squad(input_file, tokenizer)\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = split_data(dataset, test_size=0.1)\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset['context'])}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset['context'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PGsXIPGfV3L",
        "outputId": "2c34b829-8698-4719-ee0c-1d73c09b7638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'PhobertTokenizer'. \n",
            "The class this function is called from is 'RobertaTokenizerFast'.\n",
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 500\n",
            "Validation dataset size: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=256,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answer\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"start\"][0]\n",
        "        end_char = answer[\"start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "mTtBk2T7frG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = Dataset.from_dict(train_dataset)\n",
        "dataset_eval = Dataset.from_dict(val_dataset)"
      ],
      "metadata": {
        "id": "mbzXC9u7fuwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_squad = dataset_train.map(preprocess_function, batched=True, remove_columns=dataset_train.column_names)\n",
        "tokenized_squad_eval = dataset_eval.map(preprocess_function, batched=True, remove_columns=dataset_eval.column_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "a17f02eaf56c41da83292ffe2c2ff980",
            "04ab845524af4f3c98ad99df54e61127",
            "acea7e731c36455c9e6426df789817fd",
            "0005666ebab14e87a406115427dbbc88",
            "0705bd75a7024040923d900149b4fc10",
            "a9eacaba2fa3420389b9c461b326dd87",
            "2df56c8b324c470e967e2e3285fdc3e4",
            "cb5655b4d0ca4d03af16c7b1d3b28f18",
            "fbe971ebd3ce4a36b1be233f18fd3729",
            "d74f61959a5a434ebe06638f35c4a31b",
            "b3c5d7da39db4b05a9bbd6b61030a620",
            "c99b6429f4ef4e8bbc0d9e132ef904ee",
            "f4aac80206614c4f82f5f5d010b1b9ec",
            "a3c4b3ebea24416ebea0c5bf15fcd970",
            "5044ebf3aef0419db56150381f646378",
            "2e2455995add4eeda941ae66cfdcacae",
            "256c005a8400411db943baec1c879004",
            "a52739ba7bfc43a3b23729dd47c8cb5e",
            "124f71fcac64472db35b72abfd78cca1",
            "481d3d5bce1b4696923571f53fa1caa1",
            "804f265d192f43d583e1b9bb3f5efab4",
            "1d5a40fa12274020ab9f1421a10cf642"
          ]
        },
        "id": "sF8KFTqLf1_x",
        "outputId": "9d1518f4-a183-41ab-ed45-32426fc10300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a17f02eaf56c41da83292ffe2c2ff980"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c99b6429f4ef4e8bbc0d9e132ef904ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qUF7w5elJtml",
        "outputId": "bc2255e9-c918-40a4-d2f3-de59c9f91fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='960' max='960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [960/960 11:24, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.952300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.624322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.461667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.393678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.383627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.396402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.374264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.427243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.413757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.475958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.507047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.501420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.495733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.543827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.499258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.558298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.584345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.580011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.595446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.587610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.613554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.636627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.626833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.602853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.627224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.628713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.632561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.635811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.609820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.614977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=960, training_loss=0.3100018600622813, metrics={'train_runtime': 686.4843, 'train_samples_per_second': 21.85, 'train_steps_per_second': 1.398, 'total_flos': 1959725675520000.0, 'train_loss': 0.3100018600622813, 'epoch': 30.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# Sử dụng DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer, return_tensors='pt')\n",
        "\n",
        "# Cấu hình các tham số huấn luyện\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"phobert_law\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=30,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_squad,\n",
        "    eval_dataset=tokenized_squad_eval,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Da8ldY-4Anlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d85c759-550a-4883-f3f7-c07126b7064a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/modelgiaoduc/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/modelgiaoduc/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/modelgiaoduc/vocab.json',\n",
              " '/content/drive/MyDrive/modelgiaoduc/merges.txt',\n",
              " '/content/drive/MyDrive/modelgiaoduc/added_tokens.json',\n",
              " '/content/drive/MyDrive/modelgiaoduc/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "path = \"/content/drive/MyDrive/modelgiaoduc\"\n",
        "\n",
        "trainer.save_model(path)\n",
        "tokenizer.save_pretrained(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model"
      ],
      "metadata": {
        "id": "4fC5EVkNxWCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = '/content/drive/MyDrive/model_giaoduc/updateDataGd.json'\n",
        "\n",
        "dataset = load_and_preprocess_squad(input_file, tokenizer)\n",
        "\n",
        "train_dataset, val_dataset = split_data(dataset, test_size=0.1)"
      ],
      "metadata": {
        "id": "ik1zLaoqu6gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/MyDrive/model_giaoduc'\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(model_save_path)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_save_path)"
      ],
      "metadata": {
        "id": "LrASqXeNxp_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_question_length(question, max_length=258):\n",
        "    if len(question) > max_length:\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "ns6Fer-O70Gm"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, context, model, tokenizer):\n",
        "    if check_question_length(question):\n",
        "        return \"câu hỏi quá dài!\"\n",
        "    inputs = tokenizer(question.lower(), context, return_tensors=\"pt\",max_length=258, padding=\"max_length\", truncation=\"only_second\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    answer_start_index = outputs.start_logits.argmax()\n",
        "    answer_end_index = outputs.end_logits.argmax()\n",
        "\n",
        "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "    print(\"Context: \" + context + \"\\n\")\n",
        "    print(\"Question \" + question+ \"\\n\")\n",
        "\n",
        "    if(tokenizer.decode(predict_answer_tokens) == \"\"):\n",
        "        print(\"Answer: Chưa thể tìm thấy câu trả lời \\n\")\n",
        "        answer_result = \"Chưa thể tìm thấy câu trả lời\"\n",
        "    else:\n",
        "        print(\"Answer: \" + tokenizer.decode(predict_answer_tokens)+ \"\\n\")\n",
        "        answer_result = tokenizer.decode(predict_answer_tokens)\n",
        "    return answer_result"
      ],
      "metadata": {
        "id": "9d1fOj6nRcCl"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques=\"Em là sinh viên khóa 05DH do bảo lưu nên hiện tại em học cùng khóa với 06DH nhưng lớp em vẫn được giữ lớp cũ nên vẫn là 05DH trong đợt đăng kí môn học vừa qua vì Trường xếp ngày đầu tiên chỉ cho khóa 06DH đăng kí nên em bị đẩy lùi xuống đăng kí sau 2 ngày mà ngày đăng kí đó tất cả các lớp thuộc khóa 06DH đều bị khóa hết không cho đăng kí em phải gọi lên xin mở để em được đăng kí nhưng khi vào được thì hầu hết các lớp đã đủ số lượng vì là năm 4 nên rất khó để có thể đủ 30 bạn lập thành danh sách xin mở lớp,em mong trong đợt đăng kí ở học kì sau Trường có thể cho khóa 05DH được đăng kí cùng đợt với khóa 06DH vì số lượng bảo lưu như em rất ít nếu đăng kí lùi như đợt này nữa chúng em sẽ gặp nhiều khó khăn trong thực tập, đồ án em mong Thầy (Cô) xem xét điều chỉnh giúp em. Em cảm ơn.\"\n",
        "contx=\"chào em; do phân luồng theo hệ để đăng ký môn học không bị nghẽn; nếu em gặp trục trặc môn nào trong đợt đăng ký có thể lên phòng đào tạo để cô hỗ trợ\"\n",
        "answer_question(ques,contx, model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "szB9buXdylRo",
        "outputId": "6dcb8763-6f0d-4bbf-de28-17940c290f83"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'câu hỏi quá dài!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "def normalize_answer(s):\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(lower(s))\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    pred_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(pred_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = num_same / len(pred_tokens)\n",
        "    recall = num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    return normalize_answer(prediction) == normalize_answer(ground_truth)\n",
        "\n",
        "\n",
        "def evaluate_model(val_dataset, model, tokenizer):\n",
        "    f1 = 0\n",
        "    em = 0\n",
        "    total = len(val_dataset['context'])\n",
        "\n",
        "    for i in range(total):\n",
        "      context = val_dataset['context'][i]\n",
        "      question = val_dataset['question'][i]\n",
        "      true_answer = val_dataset['answer'][i]['text'][0]\n",
        "\n",
        "      predicted_answer = answer_question(question, context, model, tokenizer)\n",
        "      f1 += f1_score(predicted_answer, true_answer)\n",
        "      em += exact_match_score(predicted_answer, true_answer)\n",
        "\n",
        "    f1 = f1 / total\n",
        "    em = em / total\n",
        "    return f1, em"
      ],
      "metadata": {
        "id": "kxqc_FaWwMmY"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1, em = evaluate_model(val_dataset, model, tokenizer)\n",
        "print(f\"Validation F1 Score: {f1 * 100:.2f}%\")\n",
        "print(f\"Validation Exact Match Score: {em * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVli81G7wZlN",
        "outputId": "bb9ec39d-7d3e-43f5-e5c0-bb50c483123f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Question vì gia đình em khó khăn, em muốn xin tạm dừng kết quả đang học thì liên hệ ở phòng nào ạ?\n",
            "\n",
            "Answer: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Context: chào em; em muốn được biết chuyển dc hay không; thì em liên hệ bên trường Ngoại ngữ xem họ có nhận ko nhé.\n",
            "\n",
            "Question Thưa thầy/cô, em hiện là sinh viên năm nhất chuyên ngành công nghệ thông tin, em xin hỏi là em có được xét duyệt để chuyển trường đến đại học ngoại ngữ tin học (cùng chuyên ngành công nghệ thông tin) được không ạ? Em xin cảm ơn, mong thầy/cô hồi đáp giúp em.\n",
            "\n",
            "Answer: chào em; em muốn được biết chuyển dc hay không; thì em liên hệ bên trường Ngoại ngữ xem họ có nhận ko nhé.\n",
            "\n",
            "Context: Người học không thuộc diện bị buộc thôi học, thực hiện đầy đủ nghĩa vụ và trách nhiệm theo quy định, nếu thuộc một trong các trường hợp sau được đề nghị trường cho thôi học: Người học tự xét thấy không còn khả năng hoàn thành chương trình do thời gian còn lại không đủ để hoàn thành chương trình theo quy định. Vì lý do khác phải thôi học kèm theo minh chứng cụ thể và được Hiệu trưởng chấp thuận. Trường sẽ ra quyết định buộc thôi học và xóa tên khỏi danh sách người học nếu người học thuộc một trong các trường hợp sau: Đã hết thời gian đào tạo kể cả thời gian kéo dài (theo quyết định của Hiệu trưởng) mà chưa hội đủ điều kiện để tốt nghiệp và nhận bằng. Tạm dừng học tập quá thời gian quy định. Đã bị cảnh báo học vụ  03 lần liên tục. Bị kỷ luật ở mức buộc thôi học.  Người học thuộc diện bị buộc thôi học ngoài lý do bị kỷ luật được quyền nộp đơn xin xét chuyển sang học các chương trình ở trình độ thấp hơn hoặc chương trình vừa làm vừa học tương ứng cùng ngành trong vòng 01 năm kể từ ngày có quyết định bị buộc thôi học.\n",
            "\n",
            "Question Trường hợp nào thuộc diện buộc thôi học?\n",
            "\n",
            "Answer: Trường sẽ ra quyết định buộc thôi học và xóa tên khỏi danh sách người học nếu người học thuộc một trong các trường hợp sau: Đã hết thời gian đào tạo kể cả thời gian kéo dài (theo quyết định của Hiệu trưởng) mà chưa hội đủ điều kiện để tốt nghiệp và nhận bằng. Tạm dừng học tập quá thời gian quy định. Đã bị cảnh báo học vụ 03 lần liên tục. Bị kỷ luật ở mức buộc thôi học.\n",
            "\n",
            "Context: Trường Đại học Công Thương Thành phố Hồ Chí Minh, từ ngày 01/07/2023\n",
            "\n",
            "Question HUIT là viết tắt của trường gì?\n",
            "\n",
            "Answer: Trường Đại học Công Thương Thành phố Hồ Chí Minh, từ ngày 01/07/2023\n",
            "\n",
            "Context: chào em cụ thể môn gì vậy em\n",
            "\n",
            "Question Cho em hỏi sao điểm thi của em vẫn chưa có ạ , mà bạn em thì có rồi\n",
            "\n",
            "Answer: chào em cụ thể môn gì vậy em\n",
            "\n",
            "Context: chào em; ở trạng thái rút học phần vẫn có thể đóng học phí mà em.\n",
            "\n",
            "Question Cho em hỏi thời gian nộp học phí đến hết ngày 18/3/2019 nhưng sao học phần của em hiện giờ lại bị ở trạng thái rút học phần hầu như là hết chỉ chừa mỗi Anh Văn A1 thôi là như thế nào ạ? Xin cảm ơn\n",
            "\n",
            "Answer: chào em; ở trạng thái rút học phần vẫn có thể đóng học phí mà em.\n",
            "\n",
            "Context: Chào em, em lên Phòng đào tạo gặp trực tiếp Cô Thúy nhé. Trân trọng!\n",
            "\n",
            "Question em có thắc mắc về kết quả tốt nghiệp thì hỏi chỗ nào?\n",
            "\n",
            "Answer: Chào em, em lên Phòng đào tạo gặp trực tiếp\n",
            "\n",
            "Context: Em liên hệ phòng Kế hoạch – Tài chính để được hỗ trợ\n",
            "\n",
            "Question Em muốn xin đóng học phí đợt 1 hk2 để có lịch thi ạ.\n",
            "\n",
            "Answer: Em liên hệ phòng Kế hoạch – Tài chính để được hỗ trợ\n",
            "\n",
            "Context: Em trực tiếp lên phòng Đào tạo gặp cô Thúy để được tư vấn nha, cô sẽ hướng dẫn cho em\n",
            "\n",
            "Question em muốn phản hồi về kết quả học tập?\n",
            "\n",
            "Answer: Em trực tiếp lên phòng Đào tạo gặp cô Thúy để được tư vấn nha, cô sẽ hướng dẫn cho em\n",
            "\n",
            "Context: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Question vì gia đình đang kẹt tiền, em muốn xin tạm dừng kết quả học tập trong một thời gian thì liên hệ ở phòng nào ạ?\n",
            "\n",
            "Answer: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Context: chào em; em liên hệ trực tiếp ở khoa công nghệ thực phẩm hỏi nhé em\n",
            "\n",
            "Question Giảng viên dạy em, công bố trong đề cương khóa 08 là tính thang 5:5 nên em mới thắc mắc ạ\n",
            "\n",
            "Answer: chào em; em liên hệ trực tiếp ở khoa công nghệ thực phẩm hỏi nhé em\n",
            "\n",
            "Context: chào em; do nhà trường đang mở khóa cho giảng viên nhập điểm; em đợi kết thúc đợt nhập điểm nhà trường khóa điểm sẽ được thấy trên hệ thống nhé\n",
            "\n",
            "Question Chào Khoa . Sau khi thi xong môn kế toán chi phí thì đã có điểm thi trên trang web trường lâu rùi. Tự dưng hôm qua khi có điểm quá trình môn kế toán chi phí, thì lại mất điểm thi môn kế toán chi phí. Em cám ơn!\n",
            "\n",
            "Answer: chào em; do nhà trường đang mở khóa cho giảng viên nhập điểm; em đợi kết thúc đợt nhập điểm nhà trường khóa điểm sẽ được thấy trên hệ thống nhé\n",
            "\n",
            "Context: chào em; em cứ coi trên web nhé em.\n",
            "\n",
            "Question Xin chào Thầy cô . Cho em hỏi hiện tại e thấy điểm tổng TBC tích lũy trên web và trên ap khác nhau là sao ah . Và điểm ở đâu là đúng . Em cám ơn\n",
            "\n",
            "Answer: chào em; em cứ coi trên web nhé em.\n",
            "\n",
            "Context: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Question phòng nào hỗ trợ đăng ký học lại vậy ạ?\n",
            "\n",
            "Answer: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Context: chào em; em vào phần đk môn học; nếu có môn cần đăng ký còn mở thì em đăng ký học nhé.\n",
            "\n",
            "Question ad cho em hỏi là bây giờ em có bị học lại 1 môn mà em muốn đki học lại thì phải làm sao ạ\n",
            "\n",
            "Answer: chào em; em vào phần đk môn học; nếu có môn cần đăng ký còn mở thì em đăng ký học nhé.\n",
            "\n",
            "Context: Lớp học là những người học trúng tuyển cùng khóa tuyển sinh, học chung một chương trình đào tạo sẽ tổ chức thành một hoặc nhiều lớp học. Lớp học phần là lớp của người học cùng đăng ký một học phần, có cùng thời khóa biểu của học phần trong cùng một học kỳ. M\n",
            "\n",
            "Question Nếu đã đề nghị mở lớp học phần mà sinh viên đăng ký không đủ sỉ số tối thiểu theo quy định thì lớp học phần đó có bị hủy không?\n",
            "\n",
            "Answer: Lớp học là những người học trúng tuyển cùng khóa tuyển sinh, học chung một chương trình đào tạo sẽ tổ chức thành một hoặc nhiều lớp học. Lớp học phần là lớp của người học cùng đăng ký một học phần, có cùng thời khóa biểu của học phần trong cùng một học kỳ.\n",
            "\n",
            "Context: chào em; từ ngày 22-27/7 nhà trường sẽ cập nhật điểm em nhé\n",
            "\n",
            "Question Điểm thi phúc khảo của em được thay đổi từ ngày 21/6 mà đến nay chưa cập nhật\n",
            "\n",
            "Answer: chào em; từ ngày 22-27/7 nhà trường sẽ cập nhật điểm em nhé\n",
            "\n",
            "Context: Em trực tiếp lên phòng Đào tạo gặp cô Thúy để được tư vấn nha, cô sẽ hướng dẫn cho em\n",
            "\n",
            "Question Em muốn học thêm để lấy bằng kỹ sư. Mong trường mình hồi đáp nhanh nhất và hướng dẫn cho em xin cảm ơn ạ!\n",
            "\n",
            "Answer: Em trực tiếp lên phòng Đào tạo gặp\n",
            "\n",
            "Context: chào em; không đổi học phần được nữa nhé.\n",
            "\n",
            "Question Kính gửi\n",
            "\n",
            "Answer: chào em; không đổi học phần được nữa nhé.\n",
            "\n",
            "Context: Học phần tương đương khi học phần A gọi là tương đương với học phần B khi hai học phần này có nội dung tương đồng hoặc cùng có chuẩn đầu ra đáp ứng yêu cầu về chauarn đầu ra của chương trình đào tạo, theo các tiêu chí do khoa quản lý hoặc bộ môn phụ trách xá\n",
            "\n",
            "Question Học phần thay thế là gì?\n",
            "\n",
            "Answer: Học phần tương đương khi học phần A gọi là tương đương với học phần B khi hai học phần này có nội dung tương\n",
            "\n",
            "Context: chào em; khóa học của em là 2013-2017; (được kéo dài thêm 2 năm để trả nợ) vậy em còn thời gian rất ít; nếu em ko trả nợ kịp thì em làm đơn xin chuyển hệ đào tạo sang vừa học vừa làm để trả nợ tiếp nhé em.\n",
            "\n",
            "Question Em là sinh viên đại học khoá 04 còn nợ nhiều môn và không trả nợ kịp trong năm nay. Em cần phải làm đơn gì để được tiếp tục học ạ\n",
            "\n",
            "Answer: chào em; khóa học của em là 2013-2017; (được kéo dài thêm 2 năm để trả nợ) vậy em còn thời gian rất ít; nếu em ko trả nợ kịp thì em làm đơn xin chuyển hệ đào tạo sang vừa học vừa làm để trả nợ tiếp nhé em.\n",
            "\n",
            "Context: Em trực tiếp lên phòng Đào tạo gặp cô Thúy để được tư vấn nha, cô sẽ hướng dẫn cho em\n",
            "\n",
            "Question Dạ cho em hỏi về vấn đề xin xét miễn học thể chất vì bị chấn thương hậu phẫu thuật được không ạ, em cảm ơn\n",
            "\n",
            "Answer: Em trực tiếp lên phòng Đào tạo gặp\n",
            "\n",
            "Context: 4.5 năm nha em\n",
            "\n",
            "Question Em học ngành quản trị kinh doanh hệ cao đẳng khóa 2014-2017. Cho em hỏi thời gian học tối đa cho ngành của em là bao lâu ạ? Em cảm ơn.\n",
            "\n",
            "Answer: 4.5 năm nha em\n",
            "\n",
            "Context: em liên hệ phòng Công tác sinh viên và Thanh tra giáo dục – Tầng trệt nhà E để được tư vấn\n",
            "\n",
            "Question Dạ em kính chào quý thầy cô ạ. Em xin lỗi vì đã không thấy thông báo của trường về việc đăng ký bảo hiểm y tế lần 3 ạ, các thầy cô cho em hỏi bây giờ nếu em muốn đăng ký bảo hiểm y tế thì phải làm sao ạ? Em xin cảm ơn các thầy cô\n",
            "\n",
            "Answer: em liên hệ phòng Công tác sinh viên và Thanh tra giáo dục – Tầng trệt nhà E để được tư vấn\n",
            "\n",
            "Context: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Question em muốn đăng ký học ngành 2?\n",
            "\n",
            "Answer: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Context: chào em; anh văn A2 hiên tại đã đầy sĩ số; em chờ đợt 2 nếu mở thêm nhóm em đăng ký nha\n",
            "\n",
            "Question Em xin chào phòng Đào tạo, cho em hỏi: em mới học đến học phần anh văn A1, em muốn đăng ký học tiếp học phần anh văn A2 mà em thấy trên mạng chỉ có học phần anh văn B1 thôi thì em phải làm sao? Em chân thành cảm ơn\n",
            "\n",
            "Answer: chào em; anh văn A2 hiên tại đã đầy sĩ số; em chờ đợt 2 nếu mở thêm nhóm em đăng ký nha\n",
            "\n",
            "Context: Chào em, em lên Phòng đào tạo gặp trực tiếp Cô Thúy nhé. Trân trọng!\n",
            "\n",
            "Question em muốn biết cách xếp loại tốt nghiệp thì làm sao?\n",
            "\n",
            "Answer: Chào em, em lên Phòng đào tạo gặp trực tiếp\n",
            "\n",
            "Context: Liên hệ phòng công tác sinh viên và thanh tra giáo dục nha em.\n",
            "\n",
            "Question Cho em xin hỏi:em giờ không nhớ mật khẩu đăng nhập cần lấy lại mật khẩu thì làm sao được ạ?\n",
            "\n",
            "Answer: Liên hệ phòng công tác sinh viên và thanh tra giáo dục nha em\n",
            "\n",
            "Context: Lớp học là những người học trúng tuyển cùng khóa tuyển sinh, học chung một chương trình đào tạo sẽ tổ chức thành một hoặc nhiều lớp học. Lớp học phần là lớp của người học cùng đăng ký một học phần, có cùng thời khóa biểu của học phần trong cùng một học kỳ. Mỗi lớp học phần được gán một mã số riêng. Số lượng người học của một lớp học phần được giới hạn bởi sức chứa của phòng học hoặc đượ sắp xếp theo các yêu cầu riêng đặc thù của học phần. Số lượng người học tối thiểu cho mỗi lớp học phần quy định\n",
            "\n",
            "Question Lớp học là gì?\n",
            "\n",
            "Answer: Lớp học là những người học trúng tuyển cùng khóa tuyển sinh, học chung một chương trình đào tạo sẽ tổ chức thành một hoặc nhiều lớp học.\n",
            "\n",
            "Context: chào em; hiện tại đã hết hạn hủy học phần rồi nhé em\n",
            "\n",
            "Question Vào ngày 3/7/2019, em thực hiện phần đăng kí kỹ năng mềm do trường mở ra. Nhưng e đã đăng kí nhầm phần kỹ năng đàm phán của ngành khác. Nay e kính mong trường có thể cho e hủy học phần đó. Em chân thành cảm ơn ạ\n",
            "\n",
            "Answer: chào em; hiện tại đã hết hạn hủy học phần rồi nhé em\n",
            "\n",
            "Context: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Question em muốn xin chuyển đến học ở Trường Đại học Công Thương Thành phố Hồ Chí Minh?\n",
            "\n",
            "Answer: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Context: Quy trình đăng ký học phần: Người học xem chương trình đào tạo trong từng học kỳ, danh sách các học phần bắt buộc và tự chọn, điều kiện tiên quyết để được đăng ký học cho từng học phần tại cổng thông tin sinh viên. Trong mỗi học kỳ chính thường có hai đến ba\n",
            "\n",
            "Question Nếu nhóm học phần sinh viên đã ký mà bị hủy thì sinh viên xem thông tin ở đâu và đăng ký như thế nào?\n",
            "\n",
            "Answer: Quy trình đăng ký học phần: Người học xem chương trình đào tạo trong từng học kỳ, danh sách các học phần bắt buộc và tự chọn, điều kiện tiên quyết để được đăng ký học cho từng học phần tại cổng thông tin sinh viên.\n",
            "\n",
            "Context: Chào em; hiện tại Môn thí nghiệm vật lý không còn nữa; em có thể đăng ký học môn Vật lý đại cương 3 để thay thế nha em\n",
            "\n",
            "Question Dạ em chào thầy cô ạ. E là sinh viên khoá 06. Do 1 số sai sót nên môn Thí nghiệm vật lý e chưa đăng kí học phần. Dạ thầy cô có thể cho e biết được môn học phần tương đương của môn này không ạ. E cảm ơn ạ\n",
            "\n",
            "Answer: Chào em; hiện tại Môn thí nghiệm vật lý không còn nữa; em có thể đăng ký học môn Vật lý đại cương 3 để thay thế nha em\n",
            "\n",
            "Context: em liên hệ phòng Công tác sinh viên và Thanh tra giáo dục – Tầng trệt nhà E để được tư vấn\n",
            "\n",
            "Question Em không biết chức năng này có đang hoạt động hay không. Nhưng em đã gửi một bài tương tự cho phòng CTSV và TTGD nhưng không nhận được phản hồi. Nếu nó thực sự là đang hoạt động thì em mong sẽ nhận được phản hồi tại đây ạ\n",
            "\n",
            "Answer: em liên hệ phòng Công tác sinh viên và Thanh tra giáo dục – Tầng trệt nhà E để được tư vấn\n",
            "\n",
            "Context: liên hệ Trung tâm GD Thể chất quốc phòng để được hướng dẫn\n",
            "\n",
            "Question thưa thầy, cô có thể mở thêm giáo dục thể chất 2 bóng chuyền được không ạ, có rất nhiều sinh viên muốn học trên fanpage ạ, mùa đông mà mở bơi thì hơi lạnh, mong nhà trường giúp đỡ có thêm lớp.\n",
            "\n",
            "Answer: liên hệ Trung tâm GD Thể chất quốc phòng để được hướng dẫn\n",
            "\n",
            "Context: Em liên hệ phòng Kế hoạch – Tài chính để được hỗ trợ\n",
            "\n",
            "Question Em đã đóng học phí ngày 7 tháng 3, nhưng trang web bảo 'nợ học phí' (vì hạn chót nộp học phí là 8/3/2024).\n",
            "\n",
            "Answer: Em liên hệ phòng Kế hoạch – Tài chính để được hỗ trợ\n",
            "\n",
            "Context: chào em; hiện tại không được hủy môn học nữa nha em\n",
            "\n",
            "Question Kính gửi phòng đào tạo. Em có đăng ký môn “ quản trị chiến lược” nhưng vì đó là môn học vượt. Nên em mong phòng đào tạo có thể huỷ giúp em môn đó với ạ. Để e có thể đăng ký môn “GDQP3-AB“ ạ . Em cảm ơn phòng đào tạo\n",
            "\n",
            "Answer: chào em; hiện tại không được hủy môn học nữa nha em\n",
            "\n",
            "Context: Tín chỉ học phí là một đơn vị dùng để lượng hóa chi phí của các hoạt động giảng dạy, học tập tính cho từng học phần. Mức tiền học phí của 01 tín chỉ học phí do Hiệu trưởng quy định cho từng bậc đào tạo, hình thức đào tạo. Học phí tính theo mỗi học kỳ mà người học theo học tại HUFI. Học phí học kỳ được xác định căn cứ vào số tín chỉ học phần của người đăng ký trong thời khóa biểu học kỳ. Học phí học kỳ được tính bằng tổng của mức học phí lý thuyết nhân với số tín chỉ lý thuyết và mức học phí thực hành nhân với số tín chỉ thực hành. Học phí của các học phần người học đã đăng ký được thể hiện trên cổng thông tin sinh viên của từng người học. Trường hợp có khó khăn đột đột xuất sinh viên phải nộp đơn gia hạn tại phòng Công tác sinh viên và Thanh tra giáo dục.\n",
            "\n",
            "Question Nếu sinh viên gặp khó khắn đột xuất không có khả năng đóng học phí thì sinh viên phải làm gì?\n",
            "\n",
            "Answer: Chưa thể tìm thấy câu trả lời \n",
            "\n",
            "Context: Khóa học là thời gian thiết kế để người học hoàn thành một chương trình. Chương trình đào tạo liên thông cao đẳng lên đại học hệ chính quy cấp bằng cử nhân có 3 học kỳ (1.5 năm) tối đa 6 học kỳ (3 năm). Chương trình đào tạo liên thông cao đẳng lên đại học hệ\n",
            "\n",
            "Question Chương trình đào tạo cao đẳng lên đại học chính quy cấp bằng kỹ sư học mấy năm?\n",
            "\n",
            "Answer: Chương trình đào tạo liên thông cao đẳng lên đại học hệ\n",
            "\n",
            "Context: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Question học xong nhận bằng tốt nghiệp ở đâu?\n",
            "\n",
            "Answer: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Context: Chào em, em lên Phòng đào tạo gặp trực tiếp Cô Thúy nhé. Trân trọng!\n",
            "\n",
            "Question em muốn hỏi kết quả xét tốt nghiệp thì hỏi ở đâu\n",
            "\n",
            "Answer: Chào em, em lên Phòng đào tạo gặp trực tiếp\n",
            "\n",
            "Context: em mang tờ giấy hoãn thi liên hệ Trung tâm khảo thí và đảm bảo chất lượng; kiểm tra ghi điểm và đưa xuống phòng đào tạo để được nhập điểm. em liên hệ Trung tâm quản lý chất lượng để hỏi điểm.\n",
            "\n",
            "Question e làm mất tờ giấy hoãn thi rồi. giờ phải làm sao ạ\n",
            "\n",
            "Answer: em liên hệ Trung tâm quản lý chất lượng để hỏi điểm.\n",
            "\n",
            "Context: Học phần A là tiên quyết của học phần B, điều kiên bắt buộc để đăng ký học học phần B là người học đã học hoàn tất học phần A và kết phải đạt yêu cầu. Học phần A là học phần trước đối với học phần B nếu như người học đã đăng ký học và có điểm thi học phần A (kể cả điểm thi chưa đạt), khi ấy người học được phép đăng ký học phần B vào các học kỳ sau. Học phần B là song hành đối với học phần A với điều kiện bắt buộc để học học phần B thì người học đã đăng ký học phần A. Người học được phép đăng ký học phần B vào cùng học kỳ với học phần A.\n",
            "\n",
            "Question Học phần A được gọi là học phần tiên quyết với học phần B thì khi chưa đạt học phần A thì có đăng ký học phần B được không?\n",
            "\n",
            "Answer: Học phần A là tiên quyết của học phần B, điều kiên bắt buộc để đăng ký học học phần B là người học đã học hoàn tất học phần A và kết phải đạt yêu cầu.\n",
            "\n",
            "Context: chào em; em muốn đổi từ ngành gì qua ngành gì em\n",
            "\n",
            "Question Dạ cho em hỏi là em muốn đổi ngành nhưng không còn giấy báo trúng tuyển thì em có được chấp nhận không ạ.\n",
            "\n",
            "Answer: chào em; em muốn đổi từ ngành gì qua ngành gì em\n",
            "\n",
            "Context: liên hệ phòng công tác sinh viên và thanh tra giáo dục hỏi em nhé.\n",
            "\n",
            "Question Cho em hỏi trường có gia hạn học phí ko\n",
            "\n",
            "Answer: liên hệ phòng công tác sinh viên và thanh tra giáo dục hỏi em nhé.\n",
            "\n",
            "Context: chào em; cô kiểm tra thầy em không có điểm tiểu luận; còn điểm cuối kỳ cả lớp chưa có em nhé\n",
            "\n",
            "Question Dạ thầy cô kiểm tra giúp em với ạ, môn kĩ năng học tập hiệu quả học hè vừa rồi, em có đi thi, khi nộp bài cũng có kí tên nhưng tại sao điểm của e lại là 0 điểm ạ, thầy cô kiểm tra giúp em với ạ\n",
            "\n",
            "Answer: chào em; cô kiểm tra thầy em không có điểm tiểu luận; còn điểm cuối kỳ cả lớp chưa có em nhé\n",
            "\n",
            "Context: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Question em hiện tại là sinh viên trường khác, em muốn xin chuyển đến học ở HUIT?\n",
            "\n",
            "Answer: Phòng Đào tạo – tầng trệt nhà C\n",
            "\n",
            "Context: theo tiến độ thì khoảng 3/6 đến 23/6 em nhé em đợi thông báo cụ thể về lịch thi của nhà trường nha em.\n",
            "\n",
            "Question Cho em hỏi lịch thi HK2 của khoa công nghệ thực phẩm trong đợt 2 bắt đầu từ ngày nào ạ?\n",
            "\n",
            "Answer: theo tiến độ thì khoảng 3/6 đến 23/6 em nhé em đợi thông báo cụ thể về lịch thi của nhà trường nha em.\n",
            "\n",
            "Validation F1 Score: 75.67%\n",
            "Validation Exact Match Score: 64.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Đưa model về thiết bị (CPU hoặc GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc_MV4e5wt9s",
        "outputId": "71162b61-9790-49bd-d81a-ee5d8e31455c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForQuestionAnswering(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a17f02eaf56c41da83292ffe2c2ff980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04ab845524af4f3c98ad99df54e61127",
              "IPY_MODEL_acea7e731c36455c9e6426df789817fd",
              "IPY_MODEL_0005666ebab14e87a406115427dbbc88"
            ],
            "layout": "IPY_MODEL_0705bd75a7024040923d900149b4fc10"
          }
        },
        "04ab845524af4f3c98ad99df54e61127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9eacaba2fa3420389b9c461b326dd87",
            "placeholder": "​",
            "style": "IPY_MODEL_2df56c8b324c470e967e2e3285fdc3e4",
            "value": "Map: 100%"
          }
        },
        "acea7e731c36455c9e6426df789817fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb5655b4d0ca4d03af16c7b1d3b28f18",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbe971ebd3ce4a36b1be233f18fd3729",
            "value": 500
          }
        },
        "0005666ebab14e87a406115427dbbc88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74f61959a5a434ebe06638f35c4a31b",
            "placeholder": "​",
            "style": "IPY_MODEL_b3c5d7da39db4b05a9bbd6b61030a620",
            "value": " 500/500 [00:00&lt;00:00, 2889.96 examples/s]"
          }
        },
        "0705bd75a7024040923d900149b4fc10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9eacaba2fa3420389b9c461b326dd87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2df56c8b324c470e967e2e3285fdc3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb5655b4d0ca4d03af16c7b1d3b28f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbe971ebd3ce4a36b1be233f18fd3729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d74f61959a5a434ebe06638f35c4a31b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c5d7da39db4b05a9bbd6b61030a620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c99b6429f4ef4e8bbc0d9e132ef904ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4aac80206614c4f82f5f5d010b1b9ec",
              "IPY_MODEL_a3c4b3ebea24416ebea0c5bf15fcd970",
              "IPY_MODEL_5044ebf3aef0419db56150381f646378"
            ],
            "layout": "IPY_MODEL_2e2455995add4eeda941ae66cfdcacae"
          }
        },
        "f4aac80206614c4f82f5f5d010b1b9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_256c005a8400411db943baec1c879004",
            "placeholder": "​",
            "style": "IPY_MODEL_a52739ba7bfc43a3b23729dd47c8cb5e",
            "value": "Map: 100%"
          }
        },
        "a3c4b3ebea24416ebea0c5bf15fcd970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_124f71fcac64472db35b72abfd78cca1",
            "max": 56,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_481d3d5bce1b4696923571f53fa1caa1",
            "value": 56
          }
        },
        "5044ebf3aef0419db56150381f646378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804f265d192f43d583e1b9bb3f5efab4",
            "placeholder": "​",
            "style": "IPY_MODEL_1d5a40fa12274020ab9f1421a10cf642",
            "value": " 56/56 [00:00&lt;00:00, 1153.17 examples/s]"
          }
        },
        "2e2455995add4eeda941ae66cfdcacae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256c005a8400411db943baec1c879004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52739ba7bfc43a3b23729dd47c8cb5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "124f71fcac64472db35b72abfd78cca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "481d3d5bce1b4696923571f53fa1caa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "804f265d192f43d583e1b9bb3f5efab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5a40fa12274020ab9f1421a10cf642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}