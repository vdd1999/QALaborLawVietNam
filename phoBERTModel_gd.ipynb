{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwQwex2XqQyf",
        "outputId": "600673df-24a5-4cdf-a997-20a0e5418b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=93fab41baa49785e2a8fd02a0c009aa469fd3710fcaf46cc278c92a14437211b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: xxhash, requests, pyarrow, dill, rouge_score, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 rouge_score-0.1.2 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install datasets rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnWjdXbskRW2",
        "outputId": "dd2cc19c-eeef-4021-ad90-8467ff5c1cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvITVD2eqXoL"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from transformers import RobertaTokenizerFast, DefaultDataCollator, TrainingArguments, Trainer, AutoModelForQuestionAnswering\n",
        "from datasets import Dataset\n",
        "import json\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38pRYAo6Qc4c",
        "outputId": "f5f8db54-cecf-406b-a21c-ded7f84673a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMeWNHiAqlYm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def update_answer_starts_and_filter(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    updated_data = {\"version\": data.get(\"version\", \"\"), \"data\": []}\n",
        "\n",
        "    for article in data['data']:\n",
        "        updated_article = {\"title\": article.get(\"title\", \"\"), \"paragraphs\": []}\n",
        "\n",
        "        for paragraph in article['paragraphs']:\n",
        "            context = paragraph['context']\n",
        "            updated_paragraph = {\"context\": context, \"qas\": []}\n",
        "\n",
        "            for qa in paragraph['qas']:\n",
        "                updated_qa = {\"question\": qa['question'], \"id\": qa['id'], \"answers\": []}\n",
        "\n",
        "                for answer in qa['answers']:\n",
        "                    answer_text = answer['text']\n",
        "                    answer_start = context.find(answer_text)\n",
        "                    if answer_start != -1:\n",
        "                        updated_qa['answers'].append({\"text\": answer_text, \"answer_start\": answer_start})\n",
        "\n",
        "                if updated_qa['answers']:\n",
        "                    updated_paragraph['qas'].append(updated_qa)\n",
        "\n",
        "            if updated_paragraph['qas']:\n",
        "                updated_article['paragraphs'].append(updated_paragraph)\n",
        "\n",
        "        if updated_article['paragraphs']:\n",
        "            updated_data['data'].append(updated_article)\n",
        "\n",
        "    return updated_data\n",
        "\n",
        "def save_updated_data(data, output_file_path):\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "input_file_path = '/content/drive/MyDrive/model_giaoduc/datagd.json'\n",
        "output_file_path = '/content/drive/MyDrive/model_giaoduc/updateDataGd.json'\n",
        "\n",
        "updated_data = update_answer_starts_and_filter(input_file_path)\n",
        "save_updated_data(updated_data, output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdN_-URaHP1j"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file JSON\n",
        "with open('/content/drive/MyDrive/model_giaoduc/updateDataGd.json', 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "contexts = []\n",
        "questions = []\n",
        "answers = []\n",
        "for article in data['data']:\n",
        "    for paragraph in article['paragraphs']:\n",
        "        context = paragraph['context']\n",
        "        for qa in paragraph['qas']:\n",
        "            question = qa['question']\n",
        "            answer = qa['answers'][0]['text'] if qa['answers'] else None\n",
        "            answer_start = context.find(answer) if answer else None\n",
        "            if answer:\n",
        "                contexts.append(context)\n",
        "                questions.append(question)\n",
        "                answers.append({\n",
        "                    \"text\": [answer],\n",
        "                    \"start\": [answer_start]\n",
        "                })\n",
        "\n",
        "# Chuy·ªÉn d·ªØ li·ªáu th√†nh ƒë·ªãnh d·∫°ng list of tuples\n",
        "data = list(zip(contexts, questions, answers))\n",
        "\n",
        "# Chia d·ªØ li·ªáu th√†nh train v√† val (80% train, 20% temp)\n",
        "train_data, val_data = train_test_split(data, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu tr·ªü l·∫°i th√†nh c√°c dictionary ƒë·ªÉ l∆∞u v√†o file JSON\n",
        "def convert_to_dict(data):\n",
        "    contexts, questions, answers = zip(*data)\n",
        "    return {\n",
        "        'context': list(contexts),\n",
        "        'question': list(questions),\n",
        "        'answer': list(answers)\n",
        "    }\n",
        "\n",
        "train_dict = convert_to_dict(train_data)\n",
        "val_dict = convert_to_dict(val_data)\n",
        "\n",
        "# L∆∞u d·ªØ li·ªáu v√†o c√°c file JSON\n",
        "with open('train_data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(train_dict, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "with open('val_data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(val_dict, f, ensure_ascii=False, indent=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_and_preprocess_squad(input_file, tokenizer, max_length=258):\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    for article in data['data']:\n",
        "        for paragraph in article['paragraphs']:\n",
        "            context = paragraph['context']\n",
        "            for qa in paragraph['qas']:\n",
        "                question = qa['question']\n",
        "                answer = qa['answers'][0]['text'] if qa['answers'] else None\n",
        "                answer_start = qa['answers'][0]['answer_start'] if qa['answers'] else None\n",
        "                if answer:\n",
        "                    # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p context l·ªõn h∆°n max_length\n",
        "                    if len(tokenizer.encode(context)) > max_length:\n",
        "                        start_pos = max(0, answer_start - max_length // 2)\n",
        "                        end_pos = min(len(context), start_pos + max_length)\n",
        "                        context = context[start_pos:end_pos]\n",
        "                        answer_start = context.find(answer)\n",
        "\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    if not isinstance(answer_start, (int, float)):\n",
        "                        answer_start = 0\n",
        "                    answers.append({\n",
        "                        \"text\": [answer.lower()],\n",
        "                        \"start\": [answer_start]\n",
        "                    })\n",
        "\n",
        "    # Ki·ªÉm tra ƒë·ªô d√†i c·ªßa c√°c c·ªôt\n",
        "    assert len(contexts) == len(questions) == len(answers)\n",
        "\n",
        "    # T·∫°o t·ª´ ƒëi·ªÉn d·ªØ li·ªáu\n",
        "    dataset = {\n",
        "        'context': contexts,\n",
        "        'question': questions,\n",
        "        'answer': answers\n",
        "    }\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def split_data(dataset, test_size=0.1):\n",
        "    contexts = dataset['context']\n",
        "    questions = dataset['question']\n",
        "    answers = dataset['answer']\n",
        "\n",
        "    train_contexts, val_contexts, train_questions, val_questions, train_answers, val_answers = train_test_split(\n",
        "        contexts, questions, answers, test_size=test_size, random_state=42\n",
        "    )\n",
        "\n",
        "    train_dataset = {\n",
        "        'context': train_contexts,\n",
        "        'question': train_questions,\n",
        "        'answer': train_answers\n",
        "    }\n",
        "\n",
        "    val_dataset = {\n",
        "        'context': val_contexts,\n",
        "        'question': val_questions,\n",
        "        'answer': val_answers\n",
        "    }\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q4P67bwKfUSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = '/content/drive/MyDrive/model_giaoduc/updateDataGd.json'\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('vinai/phobert-base')\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"vinai/phobert-base\")\n",
        "model.train()\n",
        "\n",
        "dataset = load_and_preprocess_squad(input_file, tokenizer)\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = split_data(dataset, test_size=0.1)\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset['context'])}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset['context'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PGsXIPGfV3L",
        "outputId": "2c34b829-8698-4719-ee0c-1d73c09b7638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'PhobertTokenizer'. \n",
            "The class this function is called from is 'RobertaTokenizerFast'.\n",
            "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 500\n",
            "Validation dataset size: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=256,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answer\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"start\"][0]\n",
        "        end_char = answer[\"start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "mTtBk2T7frG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = Dataset.from_dict(train_dataset)\n",
        "dataset_eval = Dataset.from_dict(val_dataset)"
      ],
      "metadata": {
        "id": "mbzXC9u7fuwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_squad = dataset_train.map(preprocess_function, batched=True, remove_columns=dataset_train.column_names)\n",
        "tokenized_squad_eval = dataset_eval.map(preprocess_function, batched=True, remove_columns=dataset_eval.column_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "a17f02eaf56c41da83292ffe2c2ff980",
            "04ab845524af4f3c98ad99df54e61127",
            "acea7e731c36455c9e6426df789817fd",
            "0005666ebab14e87a406115427dbbc88",
            "0705bd75a7024040923d900149b4fc10",
            "a9eacaba2fa3420389b9c461b326dd87",
            "2df56c8b324c470e967e2e3285fdc3e4",
            "cb5655b4d0ca4d03af16c7b1d3b28f18",
            "fbe971ebd3ce4a36b1be233f18fd3729",
            "d74f61959a5a434ebe06638f35c4a31b",
            "b3c5d7da39db4b05a9bbd6b61030a620",
            "c99b6429f4ef4e8bbc0d9e132ef904ee",
            "f4aac80206614c4f82f5f5d010b1b9ec",
            "a3c4b3ebea24416ebea0c5bf15fcd970",
            "5044ebf3aef0419db56150381f646378",
            "2e2455995add4eeda941ae66cfdcacae",
            "256c005a8400411db943baec1c879004",
            "a52739ba7bfc43a3b23729dd47c8cb5e",
            "124f71fcac64472db35b72abfd78cca1",
            "481d3d5bce1b4696923571f53fa1caa1",
            "804f265d192f43d583e1b9bb3f5efab4",
            "1d5a40fa12274020ab9f1421a10cf642"
          ]
        },
        "id": "sF8KFTqLf1_x",
        "outputId": "9d1518f4-a183-41ab-ed45-32426fc10300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a17f02eaf56c41da83292ffe2c2ff980"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c99b6429f4ef4e8bbc0d9e132ef904ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qUF7w5elJtml",
        "outputId": "bc2255e9-c918-40a4-d2f3-de59c9f91fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='960' max='960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [960/960 11:24, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.952300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.624322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.461667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.393678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.383627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.396402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.374264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.427243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.413757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.475958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.507047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.501420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.495733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.543827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.499258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.558298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.584345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.580011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.595446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.587610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.613554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.636627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.626833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.602853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.627224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.628713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.632561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.635811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.609820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.534900</td>\n",
              "      <td>0.614977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=960, training_loss=0.3100018600622813, metrics={'train_runtime': 686.4843, 'train_samples_per_second': 21.85, 'train_steps_per_second': 1.398, 'total_flos': 1959725675520000.0, 'train_loss': 0.3100018600622813, 'epoch': 30.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# S·ª≠ d·ª•ng DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer, return_tensors='pt')\n",
        "\n",
        "# C·∫•u h√¨nh c√°c tham s·ªë hu·∫•n luy·ªán\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"phobert_law\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=30,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_squad,\n",
        "    eval_dataset=tokenized_squad_eval,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "# Hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Da8ldY-4Anlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d85c759-550a-4883-f3f7-c07126b7064a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/modelgiaoduc/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/modelgiaoduc/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/modelgiaoduc/vocab.json',\n",
              " '/content/drive/MyDrive/modelgiaoduc/merges.txt',\n",
              " '/content/drive/MyDrive/modelgiaoduc/added_tokens.json',\n",
              " '/content/drive/MyDrive/modelgiaoduc/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "path = \"/content/drive/MyDrive/modelgiaoduc\"\n",
        "\n",
        "trainer.save_model(path)\n",
        "tokenizer.save_pretrained(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model"
      ],
      "metadata": {
        "id": "4fC5EVkNxWCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = '/content/drive/MyDrive/model_giaoduc/updateDataGd.json'\n",
        "\n",
        "dataset = load_and_preprocess_squad(input_file, tokenizer)\n",
        "\n",
        "train_dataset, val_dataset = split_data(dataset, test_size=0.1)"
      ],
      "metadata": {
        "id": "ik1zLaoqu6gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/MyDrive/model_giaoduc'\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(model_save_path)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_save_path)"
      ],
      "metadata": {
        "id": "LrASqXeNxp_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_question_length(question, max_length=258):\n",
        "    if len(question) > max_length:\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "ns6Fer-O70Gm"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, context, model, tokenizer):\n",
        "    if check_question_length(question):\n",
        "        return \"c√¢u h·ªèi qu√° d√†i!\"\n",
        "    inputs = tokenizer(question.lower(), context, return_tensors=\"pt\",max_length=258, padding=\"max_length\", truncation=\"only_second\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    answer_start_index = outputs.start_logits.argmax()\n",
        "    answer_end_index = outputs.end_logits.argmax()\n",
        "\n",
        "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "    print(\"Context: \" + context + \"\\n\")\n",
        "    print(\"Question \" + question+ \"\\n\")\n",
        "\n",
        "    if(tokenizer.decode(predict_answer_tokens) == \"\"):\n",
        "        print(\"Answer: Ch∆∞a th·ªÉ t√¨m th·∫•y c√¢u tr·∫£ l·ªùi \\n\")\n",
        "        answer_result = \"Ch∆∞a th·ªÉ t√¨m th·∫•y c√¢u tr·∫£ l·ªùi\"\n",
        "    else:\n",
        "        print(\"Answer: \" + tokenizer.decode(predict_answer_tokens)+ \"\\n\")\n",
        "        answer_result = tokenizer.decode(predict_answer_tokens)\n",
        "    return answer_result"
      ],
      "metadata": {
        "id": "9d1fOj6nRcCl"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques=\"Em l√† sinh vi√™n kh√≥a 05DH do b·∫£o l∆∞u n√™n hi·ªán t·∫°i em h·ªçc c√πng kh√≥a v·ªõi 06DH nh∆∞ng l·ªõp em v·∫´n ƒë∆∞·ª£c gi·ªØ l·ªõp c≈© n√™n v·∫´n l√† 05DH trong ƒë·ª£t ƒëƒÉng k√≠ m√¥n h·ªçc v·ª´a qua v√¨ Tr∆∞·ªùng x·∫øp ng√†y ƒë·∫ßu ti√™n ch·ªâ cho kh√≥a 06DH ƒëƒÉng k√≠ n√™n em b·ªã ƒë·∫©y l√πi xu·ªëng ƒëƒÉng k√≠ sau 2 ng√†y m√† ng√†y ƒëƒÉng k√≠ ƒë√≥ t·∫•t c·∫£ c√°c l·ªõp thu·ªôc kh√≥a 06DH ƒë·ªÅu b·ªã kh√≥a h·∫øt kh√¥ng cho ƒëƒÉng k√≠ em ph·∫£i g·ªçi l√™n xin m·ªü ƒë·ªÉ em ƒë∆∞·ª£c ƒëƒÉng k√≠ nh∆∞ng khi v√†o ƒë∆∞·ª£c th√¨ h·∫ßu h·∫øt c√°c l·ªõp ƒë√£ ƒë·ªß s·ªë l∆∞·ª£ng v√¨ l√† nƒÉm 4 n√™n r·∫•t kh√≥ ƒë·ªÉ c√≥ th·ªÉ ƒë·ªß 30 b·∫°n l·∫≠p th√†nh danh s√°ch xin m·ªü l·ªõp,em mong trong ƒë·ª£t ƒëƒÉng k√≠ ·ªü h·ªçc k√¨ sau Tr∆∞·ªùng c√≥ th·ªÉ cho kh√≥a 05DH ƒë∆∞·ª£c ƒëƒÉng k√≠ c√πng ƒë·ª£t v·ªõi kh√≥a 06DH v√¨ s·ªë l∆∞·ª£ng b·∫£o l∆∞u nh∆∞ em r·∫•t √≠t n·∫øu ƒëƒÉng k√≠ l√πi nh∆∞ ƒë·ª£t n√†y n·ªØa ch√∫ng em s·∫Ω g·∫∑p nhi·ªÅu kh√≥ khƒÉn trong th·ª±c t·∫≠p, ƒë·ªì √°n em mong Th·∫ßy (C√¥) xem x√©t ƒëi·ªÅu ch·ªânh gi√∫p em. Em c·∫£m ∆°n.\"\n",
        "contx=\"ch√†o em; do ph√¢n lu·ªìng theo h·ªá ƒë·ªÉ ƒëƒÉng k√Ω m√¥n h·ªçc kh√¥ng b·ªã ngh·∫Ωn; n·∫øu em g·∫∑p tr·ª•c tr·∫∑c m√¥n n√†o trong ƒë·ª£t ƒëƒÉng k√Ω c√≥ th·ªÉ l√™n ph√≤ng ƒë√†o t·∫°o ƒë·ªÉ c√¥ h·ªó tr·ª£\"\n",
        "answer_question(ques,contx, model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "szB9buXdylRo",
        "outputId": "6dcb8763-6f0d-4bbf-de28-17940c290f83"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c√¢u h·ªèi qu√° d√†i!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "def normalize_answer(s):\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(lower(s))\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    pred_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(pred_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = num_same / len(pred_tokens)\n",
        "    recall = num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    return normalize_answer(prediction) == normalize_answer(ground_truth)\n",
        "\n",
        "\n",
        "def evaluate_model(val_dataset, model, tokenizer):\n",
        "    f1 = 0\n",
        "    em = 0\n",
        "    total = len(val_dataset['context'])\n",
        "\n",
        "    for i in range(total):\n",
        "      context = val_dataset['context'][i]\n",
        "      question = val_dataset['question'][i]\n",
        "      true_answer = val_dataset['answer'][i]['text'][0]\n",
        "\n",
        "      predicted_answer = answer_question(question, context, model, tokenizer)\n",
        "      f1 += f1_score(predicted_answer, true_answer)\n",
        "      em += exact_match_score(predicted_answer, true_answer)\n",
        "\n",
        "    f1 = f1 / total\n",
        "    em = em / total\n",
        "    return f1, em"
      ],
      "metadata": {
        "id": "kxqc_FaWwMmY"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1, em = evaluate_model(val_dataset, model, tokenizer)\n",
        "print(f\"Validation F1 Score: {f1 * 100:.2f}%\")\n",
        "print(f\"Validation Exact Match Score: {em * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVli81G7wZlN",
        "outputId": "bb9ec39d-7d3e-43f5-e5c0-bb50c483123f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Question v√¨ gia ƒë√¨nh em kh√≥ khƒÉn, em mu·ªën xin t·∫°m d·ª´ng k·∫øt qu·∫£ ƒëang h·ªçc th√¨ li√™n h·ªá ·ªü ph√≤ng n√†o ·∫°?\n",
            "\n",
            "Answer: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Context: ch√†o em; em mu·ªën ƒë∆∞·ª£c bi·∫øt chuy·ªÉn dc hay kh√¥ng; th√¨ em li√™n h·ªá b√™n tr∆∞·ªùng Ngo·∫°i ng·ªØ xem h·ªç c√≥ nh·∫≠n ko nh√©.\n",
            "\n",
            "Question Th∆∞a th·∫ßy/c√¥, em hi·ªán l√† sinh vi√™n nƒÉm nh·∫•t chuy√™n ng√†nh c√¥ng ngh·ªá th√¥ng tin, em xin h·ªèi l√† em c√≥ ƒë∆∞·ª£c x√©t duy·ªát ƒë·ªÉ chuy·ªÉn tr∆∞·ªùng ƒë·∫øn ƒë·∫°i h·ªçc ngo·∫°i ng·ªØ tin h·ªçc (c√πng chuy√™n ng√†nh c√¥ng ngh·ªá th√¥ng tin) ƒë∆∞·ª£c kh√¥ng ·∫°? Em xin c·∫£m ∆°n, mong th·∫ßy/c√¥ h·ªìi ƒë√°p gi√∫p em.\n",
            "\n",
            "Answer: ch√†o em; em mu·ªën ƒë∆∞·ª£c bi·∫øt chuy·ªÉn dc hay kh√¥ng; th√¨ em li√™n h·ªá b√™n tr∆∞·ªùng Ngo·∫°i ng·ªØ xem h·ªç c√≥ nh·∫≠n ko nh√©.\n",
            "\n",
            "Context: Ng∆∞·ªùi h·ªçc kh√¥ng thu·ªôc di·ªán b·ªã bu·ªôc th√¥i h·ªçc, th·ª±c hi·ªán ƒë·∫ßy ƒë·ªß nghƒ©a v·ª• v√† tr√°ch nhi·ªám theo quy ƒë·ªãnh, n·∫øu thu·ªôc m·ªôt trong c√°c tr∆∞·ªùng h·ª£p sau ƒë∆∞·ª£c ƒë·ªÅ ngh·ªã tr∆∞·ªùng cho th√¥i h·ªçc: Ng∆∞·ªùi h·ªçc t·ª± x√©t th·∫•y kh√¥ng c√≤n kh·∫£ nƒÉng ho√†n th√†nh ch∆∞∆°ng tr√¨nh do th·ªùi gian c√≤n l·∫°i kh√¥ng ƒë·ªß ƒë·ªÉ ho√†n th√†nh ch∆∞∆°ng tr√¨nh theo quy ƒë·ªãnh. V√¨ l√Ω do kh√°c ph·∫£i th√¥i h·ªçc k√®m theo minh ch·ª©ng c·ª• th·ªÉ v√† ƒë∆∞·ª£c Hi·ªáu tr∆∞·ªüng ch·∫•p thu·∫≠n. Tr∆∞·ªùng s·∫Ω ra quy·∫øt ƒë·ªãnh bu·ªôc th√¥i h·ªçc v√† x√≥a t√™n kh·ªèi danh s√°ch ng∆∞·ªùi h·ªçc n·∫øu ng∆∞·ªùi h·ªçc thu·ªôc m·ªôt trong c√°c tr∆∞·ªùng h·ª£p sau: ƒê√£ h·∫øt th·ªùi gian ƒë√†o t·∫°o k·ªÉ c·∫£ th·ªùi gian k√©o d√†i (theo quy·∫øt ƒë·ªãnh c·ªßa Hi·ªáu tr∆∞·ªüng) m√† ch∆∞a h·ªôi ƒë·ªß ƒëi·ªÅu ki·ªán ƒë·ªÉ t·ªët nghi·ªáp v√† nh·∫≠n b·∫±ng. T·∫°m d·ª´ng h·ªçc t·∫≠p qu√° th·ªùi gian quy ƒë·ªãnh. ƒê√£ b·ªã c·∫£nh b√°o h·ªçc v·ª•  03 l·∫ßn li√™n t·ª•c. B·ªã k·ª∑ lu·∫≠t ·ªü m·ª©c bu·ªôc th√¥i h·ªçc.  Ng∆∞·ªùi h·ªçc thu·ªôc di·ªán b·ªã bu·ªôc th√¥i h·ªçc ngo√†i l√Ω do b·ªã k·ª∑ lu·∫≠t ƒë∆∞·ª£c quy·ªÅn n·ªôp ƒë∆°n xin x√©t chuy·ªÉn sang h·ªçc c√°c ch∆∞∆°ng tr√¨nh ·ªü tr√¨nh ƒë·ªô th·∫•p h∆°n ho·∫∑c ch∆∞∆°ng tr√¨nh v·ª´a l√†m v·ª´a h·ªçc t∆∞∆°ng ·ª©ng c√πng ng√†nh trong v√≤ng 01 nƒÉm k·ªÉ t·ª´ ng√†y c√≥ quy·∫øt ƒë·ªãnh b·ªã bu·ªôc th√¥i h·ªçc.\n",
            "\n",
            "Question Tr∆∞·ªùng h·ª£p n√†o thu·ªôc di·ªán bu·ªôc th√¥i h·ªçc?\n",
            "\n",
            "Answer: Tr∆∞·ªùng s·∫Ω ra quy·∫øt ƒë·ªãnh bu·ªôc th√¥i h·ªçc v√† x√≥a t√™n kh·ªèi danh s√°ch ng∆∞·ªùi h·ªçc n·∫øu ng∆∞·ªùi h·ªçc thu·ªôc m·ªôt trong c√°c tr∆∞·ªùng h·ª£p sau: ƒê√£ h·∫øt th·ªùi gian ƒë√†o t·∫°o k·ªÉ c·∫£ th·ªùi gian k√©o d√†i (theo quy·∫øt ƒë·ªãnh c·ªßa Hi·ªáu tr∆∞·ªüng) m√† ch∆∞a h·ªôi ƒë·ªß ƒëi·ªÅu ki·ªán ƒë·ªÉ t·ªët nghi·ªáp v√† nh·∫≠n b·∫±ng. T·∫°m d·ª´ng h·ªçc t·∫≠p qu√° th·ªùi gian quy ƒë·ªãnh. ƒê√£ b·ªã c·∫£nh b√°o h·ªçc v·ª• 03 l·∫ßn li√™n t·ª•c. B·ªã k·ª∑ lu·∫≠t ·ªü m·ª©c bu·ªôc th√¥i h·ªçc.\n",
            "\n",
            "Context: Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng Th∆∞∆°ng Th√†nh ph·ªë H·ªì Ch√≠ Minh, t·ª´ ng√†y 01/07/2023\n",
            "\n",
            "Question HUIT l√† vi·∫øt t·∫Øt c·ªßa tr∆∞·ªùng g√¨?\n",
            "\n",
            "Answer: Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng Th∆∞∆°ng Th√†nh ph·ªë H·ªì Ch√≠ Minh, t·ª´ ng√†y 01/07/2023\n",
            "\n",
            "Context: ch√†o em c·ª• th·ªÉ m√¥n g√¨ v·∫≠y em\n",
            "\n",
            "Question Cho em h·ªèi sao ƒëi·ªÉm thi c·ªßa em v·∫´n ch∆∞a c√≥ ·∫° , m√† b·∫°n em th√¨ c√≥ r·ªìi\n",
            "\n",
            "Answer: ch√†o em c·ª• th·ªÉ m√¥n g√¨ v·∫≠y em\n",
            "\n",
            "Context: ch√†o em; ·ªü tr·∫°ng th√°i r√∫t h·ªçc ph·∫ßn v·∫´n c√≥ th·ªÉ ƒë√≥ng h·ªçc ph√≠ m√† em.\n",
            "\n",
            "Question Cho em h·ªèi th·ªùi gian n·ªôp h·ªçc ph√≠ ƒë·∫øn h·∫øt ng√†y 18/3/2019 nh∆∞ng sao h·ªçc ph·∫ßn c·ªßa em hi·ªán gi·ªù l·∫°i b·ªã ·ªü tr·∫°ng th√°i r√∫t h·ªçc ph·∫ßn h·∫ßu nh∆∞ l√† h·∫øt ch·ªâ ch·ª´a m·ªói Anh VƒÉn A1 th√¥i l√† nh∆∞ th·∫ø n√†o ·∫°? Xin c·∫£m ∆°n\n",
            "\n",
            "Answer: ch√†o em; ·ªü tr·∫°ng th√°i r√∫t h·ªçc ph·∫ßn v·∫´n c√≥ th·ªÉ ƒë√≥ng h·ªçc ph√≠ m√† em.\n",
            "\n",
            "Context: Ch√†o em, em l√™n Ph√≤ng ƒë√†o t·∫°o g·∫∑p tr·ª±c ti·∫øp C√¥ Th√∫y nh√©. Tr√¢n tr·ªçng!\n",
            "\n",
            "Question em c√≥ th·∫Øc m·∫Øc v·ªÅ k·∫øt qu·∫£ t·ªët nghi·ªáp th√¨ h·ªèi ch·ªó n√†o?\n",
            "\n",
            "Answer: Ch√†o em, em l√™n Ph√≤ng ƒë√†o t·∫°o g·∫∑p tr·ª±c ti·∫øp\n",
            "\n",
            "Context: Em li√™n h·ªá ph√≤ng K·∫ø ho·∫°ch ‚Äì T√†i ch√≠nh ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£\n",
            "\n",
            "Question Em mu·ªën xin ƒë√≥ng h·ªçc ph√≠ ƒë·ª£t 1 hk2 ƒë·ªÉ c√≥ l·ªãch thi ·∫°.\n",
            "\n",
            "Answer: Em li√™n h·ªá ph√≤ng K·∫ø ho·∫°ch ‚Äì T√†i ch√≠nh ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£\n",
            "\n",
            "Context: Em tr·ª±c ti·∫øp l√™n ph√≤ng ƒê√†o t·∫°o g·∫∑p c√¥ Th√∫y ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n nha, c√¥ s·∫Ω h∆∞·ªõng d·∫´n cho em\n",
            "\n",
            "Question em mu·ªën ph·∫£n h·ªìi v·ªÅ k·∫øt qu·∫£ h·ªçc t·∫≠p?\n",
            "\n",
            "Answer: Em tr·ª±c ti·∫øp l√™n ph√≤ng ƒê√†o t·∫°o g·∫∑p c√¥ Th√∫y ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n nha, c√¥ s·∫Ω h∆∞·ªõng d·∫´n cho em\n",
            "\n",
            "Context: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Question v√¨ gia ƒë√¨nh ƒëang k·∫πt ti·ªÅn, em mu·ªën xin t·∫°m d·ª´ng k·∫øt qu·∫£ h·ªçc t·∫≠p trong m·ªôt th·ªùi gian th√¨ li√™n h·ªá ·ªü ph√≤ng n√†o ·∫°?\n",
            "\n",
            "Answer: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Context: ch√†o em; em li√™n h·ªá tr·ª±c ti·∫øp ·ªü khoa c√¥ng ngh·ªá th·ª±c ph·∫©m h·ªèi nh√© em\n",
            "\n",
            "Question Gi·∫£ng vi√™n d·∫°y em, c√¥ng b·ªë trong ƒë·ªÅ c∆∞∆°ng kh√≥a 08 l√† t√≠nh thang 5:5 n√™n em m·ªõi th·∫Øc m·∫Øc ·∫°\n",
            "\n",
            "Answer: ch√†o em; em li√™n h·ªá tr·ª±c ti·∫øp ·ªü khoa c√¥ng ngh·ªá th·ª±c ph·∫©m h·ªèi nh√© em\n",
            "\n",
            "Context: ch√†o em; do nh√† tr∆∞·ªùng ƒëang m·ªü kh√≥a cho gi·∫£ng vi√™n nh·∫≠p ƒëi·ªÉm; em ƒë·ª£i k·∫øt th√∫c ƒë·ª£t nh·∫≠p ƒëi·ªÉm nh√† tr∆∞·ªùng kh√≥a ƒëi·ªÉm s·∫Ω ƒë∆∞·ª£c th·∫•y tr√™n h·ªá th·ªëng nh√©\n",
            "\n",
            "Question Ch√†o Khoa . Sau khi thi xong m√¥n k·∫ø to√°n chi ph√≠ th√¨ ƒë√£ c√≥ ƒëi·ªÉm thi tr√™n trang web tr∆∞·ªùng l√¢u r√πi. T·ª± d∆∞ng h√¥m qua khi c√≥ ƒëi·ªÉm qu√° tr√¨nh m√¥n k·∫ø to√°n chi ph√≠, th√¨ l·∫°i m·∫•t ƒëi·ªÉm thi m√¥n k·∫ø to√°n chi ph√≠. Em c√°m ∆°n!\n",
            "\n",
            "Answer: ch√†o em; do nh√† tr∆∞·ªùng ƒëang m·ªü kh√≥a cho gi·∫£ng vi√™n nh·∫≠p ƒëi·ªÉm; em ƒë·ª£i k·∫øt th√∫c ƒë·ª£t nh·∫≠p ƒëi·ªÉm nh√† tr∆∞·ªùng kh√≥a ƒëi·ªÉm s·∫Ω ƒë∆∞·ª£c th·∫•y tr√™n h·ªá th·ªëng nh√©\n",
            "\n",
            "Context: ch√†o em; em c·ª© coi tr√™n web nh√© em.\n",
            "\n",
            "Question Xin ch√†o Th·∫ßy c√¥ . Cho em h·ªèi hi·ªán t·∫°i e th·∫•y ƒëi·ªÉm t·ªïng TBC t√≠ch l≈©y tr√™n web v√† tr√™n ap kh√°c nhau l√† sao ah . V√† ƒëi·ªÉm ·ªü ƒë√¢u l√† ƒë√∫ng . Em c√°m ∆°n\n",
            "\n",
            "Answer: ch√†o em; em c·ª© coi tr√™n web nh√© em.\n",
            "\n",
            "Context: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Question ph√≤ng n√†o h·ªó tr·ª£ ƒëƒÉng k√Ω h·ªçc l·∫°i v·∫≠y ·∫°?\n",
            "\n",
            "Answer: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Context: ch√†o em; em v√†o ph·∫ßn ƒëk m√¥n h·ªçc; n·∫øu c√≥ m√¥n c·∫ßn ƒëƒÉng k√Ω c√≤n m·ªü th√¨ em ƒëƒÉng k√Ω h·ªçc nh√©.\n",
            "\n",
            "Question ad cho em h·ªèi l√† b√¢y gi·ªù em c√≥ b·ªã h·ªçc l·∫°i 1 m√¥n m√† em mu·ªën ƒëki h·ªçc l·∫°i th√¨ ph·∫£i l√†m sao ·∫°\n",
            "\n",
            "Answer: ch√†o em; em v√†o ph·∫ßn ƒëk m√¥n h·ªçc; n·∫øu c√≥ m√¥n c·∫ßn ƒëƒÉng k√Ω c√≤n m·ªü th√¨ em ƒëƒÉng k√Ω h·ªçc nh√©.\n",
            "\n",
            "Context: L·ªõp h·ªçc l√† nh·ªØng ng∆∞·ªùi h·ªçc tr√∫ng tuy·ªÉn c√πng kh√≥a tuy·ªÉn sinh, h·ªçc chung m·ªôt ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o s·∫Ω t·ªï ch·ª©c th√†nh m·ªôt ho·∫∑c nhi·ªÅu l·ªõp h·ªçc. L·ªõp h·ªçc ph·∫ßn l√† l·ªõp c·ªßa ng∆∞·ªùi h·ªçc c√πng ƒëƒÉng k√Ω m·ªôt h·ªçc ph·∫ßn, c√≥ c√πng th·ªùi kh√≥a bi·ªÉu c·ªßa h·ªçc ph·∫ßn trong c√πng m·ªôt h·ªçc k·ª≥. M\n",
            "\n",
            "Question N·∫øu ƒë√£ ƒë·ªÅ ngh·ªã m·ªü l·ªõp h·ªçc ph·∫ßn m√† sinh vi√™n ƒëƒÉng k√Ω kh√¥ng ƒë·ªß s·ªâ s·ªë t·ªëi thi·ªÉu theo quy ƒë·ªãnh th√¨ l·ªõp h·ªçc ph·∫ßn ƒë√≥ c√≥ b·ªã h·ªßy kh√¥ng?\n",
            "\n",
            "Answer: L·ªõp h·ªçc l√† nh·ªØng ng∆∞·ªùi h·ªçc tr√∫ng tuy·ªÉn c√πng kh√≥a tuy·ªÉn sinh, h·ªçc chung m·ªôt ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o s·∫Ω t·ªï ch·ª©c th√†nh m·ªôt ho·∫∑c nhi·ªÅu l·ªõp h·ªçc. L·ªõp h·ªçc ph·∫ßn l√† l·ªõp c·ªßa ng∆∞·ªùi h·ªçc c√πng ƒëƒÉng k√Ω m·ªôt h·ªçc ph·∫ßn, c√≥ c√πng th·ªùi kh√≥a bi·ªÉu c·ªßa h·ªçc ph·∫ßn trong c√πng m·ªôt h·ªçc k·ª≥.\n",
            "\n",
            "Context: ch√†o em; t·ª´ ng√†y 22-27/7 nh√† tr∆∞·ªùng s·∫Ω c·∫≠p nh·∫≠t ƒëi·ªÉm em nh√©\n",
            "\n",
            "Question ƒêi·ªÉm thi ph√∫c kh·∫£o c·ªßa em ƒë∆∞·ª£c thay ƒë·ªïi t·ª´ ng√†y 21/6 m√† ƒë·∫øn nay ch∆∞a c·∫≠p nh·∫≠t\n",
            "\n",
            "Answer: ch√†o em; t·ª´ ng√†y 22-27/7 nh√† tr∆∞·ªùng s·∫Ω c·∫≠p nh·∫≠t ƒëi·ªÉm em nh√©\n",
            "\n",
            "Context: Em tr·ª±c ti·∫øp l√™n ph√≤ng ƒê√†o t·∫°o g·∫∑p c√¥ Th√∫y ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n nha, c√¥ s·∫Ω h∆∞·ªõng d·∫´n cho em\n",
            "\n",
            "Question Em mu·ªën h·ªçc th√™m ƒë·ªÉ l·∫•y b·∫±ng k·ªπ s∆∞. Mong tr∆∞·ªùng m√¨nh h·ªìi ƒë√°p nhanh nh·∫•t v√† h∆∞·ªõng d·∫´n cho em xin c·∫£m ∆°n ·∫°!\n",
            "\n",
            "Answer: Em tr·ª±c ti·∫øp l√™n ph√≤ng ƒê√†o t·∫°o g·∫∑p\n",
            "\n",
            "Context: ch√†o em; kh√¥ng ƒë·ªïi h·ªçc ph·∫ßn ƒë∆∞·ª£c n·ªØa nh√©.\n",
            "\n",
            "Question K√≠nh g·ª≠i\n",
            "\n",
            "Answer: ch√†o em; kh√¥ng ƒë·ªïi h·ªçc ph·∫ßn ƒë∆∞·ª£c n·ªØa nh√©.\n",
            "\n",
            "Context: H·ªçc ph·∫ßn t∆∞∆°ng ƒë∆∞∆°ng khi h·ªçc ph·∫ßn A g·ªçi l√† t∆∞∆°ng ƒë∆∞∆°ng v·ªõi h·ªçc ph·∫ßn B khi hai h·ªçc ph·∫ßn n√†y c√≥ n·ªôi dung t∆∞∆°ng ƒë·ªìng ho·∫∑c c√πng c√≥ chu·∫©n ƒë·∫ßu ra ƒë√°p ·ª©ng y√™u c·∫ßu v·ªÅ chauarn ƒë·∫ßu ra c·ªßa ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o, theo c√°c ti√™u ch√≠ do khoa qu·∫£n l√Ω ho·∫∑c b·ªô m√¥n ph·ª• tr√°ch x√°\n",
            "\n",
            "Question H·ªçc ph·∫ßn thay th·∫ø l√† g√¨?\n",
            "\n",
            "Answer: H·ªçc ph·∫ßn t∆∞∆°ng ƒë∆∞∆°ng khi h·ªçc ph·∫ßn A g·ªçi l√† t∆∞∆°ng ƒë∆∞∆°ng v·ªõi h·ªçc ph·∫ßn B khi hai h·ªçc ph·∫ßn n√†y c√≥ n·ªôi dung t∆∞∆°ng\n",
            "\n",
            "Context: ch√†o em; kh√≥a h·ªçc c·ªßa em l√† 2013-2017; (ƒë∆∞·ª£c k√©o d√†i th√™m 2 nƒÉm ƒë·ªÉ tr·∫£ n·ª£) v·∫≠y em c√≤n th·ªùi gian r·∫•t √≠t; n·∫øu em ko tr·∫£ n·ª£ k·ªãp th√¨ em l√†m ƒë∆°n xin chuy·ªÉn h·ªá ƒë√†o t·∫°o sang v·ª´a h·ªçc v·ª´a l√†m ƒë·ªÉ tr·∫£ n·ª£ ti·∫øp nh√© em.\n",
            "\n",
            "Question Em l√† sinh vi√™n ƒë·∫°i h·ªçc kho√° 04 c√≤n n·ª£ nhi·ªÅu m√¥n v√† kh√¥ng tr·∫£ n·ª£ k·ªãp trong nƒÉm nay. Em c·∫ßn ph·∫£i l√†m ƒë∆°n g√¨ ƒë·ªÉ ƒë∆∞·ª£c ti·∫øp t·ª•c h·ªçc ·∫°\n",
            "\n",
            "Answer: ch√†o em; kh√≥a h·ªçc c·ªßa em l√† 2013-2017; (ƒë∆∞·ª£c k√©o d√†i th√™m 2 nƒÉm ƒë·ªÉ tr·∫£ n·ª£) v·∫≠y em c√≤n th·ªùi gian r·∫•t √≠t; n·∫øu em ko tr·∫£ n·ª£ k·ªãp th√¨ em l√†m ƒë∆°n xin chuy·ªÉn h·ªá ƒë√†o t·∫°o sang v·ª´a h·ªçc v·ª´a l√†m ƒë·ªÉ tr·∫£ n·ª£ ti·∫øp nh√© em.\n",
            "\n",
            "Context: Em tr·ª±c ti·∫øp l√™n ph√≤ng ƒê√†o t·∫°o g·∫∑p c√¥ Th√∫y ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n nha, c√¥ s·∫Ω h∆∞·ªõng d·∫´n cho em\n",
            "\n",
            "Question D·∫° cho em h·ªèi v·ªÅ v·∫•n ƒë·ªÅ xin x√©t mi·ªÖn h·ªçc th·ªÉ ch·∫•t v√¨ b·ªã ch·∫•n th∆∞∆°ng h·∫≠u ph·∫´u thu·∫≠t ƒë∆∞·ª£c kh√¥ng ·∫°, em c·∫£m ∆°n\n",
            "\n",
            "Answer: Em tr·ª±c ti·∫øp l√™n ph√≤ng ƒê√†o t·∫°o g·∫∑p\n",
            "\n",
            "Context: 4.5 nƒÉm nha em\n",
            "\n",
            "Question Em h·ªçc ng√†nh qu·∫£n tr·ªã kinh doanh h·ªá cao ƒë·∫≥ng kh√≥a 2014-2017. Cho em h·ªèi th·ªùi gian h·ªçc t·ªëi ƒëa cho ng√†nh c·ªßa em l√† bao l√¢u ·∫°? Em c·∫£m ∆°n.\n",
            "\n",
            "Answer: 4.5 nƒÉm nha em\n",
            "\n",
            "Context: em li√™n h·ªá ph√≤ng C√¥ng t√°c sinh vi√™n v√† Thanh tra gi√°o d·ª•c ‚Äì T·∫ßng tr·ªát nh√† E ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n\n",
            "\n",
            "Question D·∫° em k√≠nh ch√†o qu√Ω th·∫ßy c√¥ ·∫°. Em xin l·ªói v√¨ ƒë√£ kh√¥ng th·∫•y th√¥ng b√°o c·ªßa tr∆∞·ªùng v·ªÅ vi·ªác ƒëƒÉng k√Ω b·∫£o hi·ªÉm y t·∫ø l·∫ßn 3 ·∫°, c√°c th·∫ßy c√¥ cho em h·ªèi b√¢y gi·ªù n·∫øu em mu·ªën ƒëƒÉng k√Ω b·∫£o hi·ªÉm y t·∫ø th√¨ ph·∫£i l√†m sao ·∫°? Em xin c·∫£m ∆°n c√°c th·∫ßy c√¥\n",
            "\n",
            "Answer: em li√™n h·ªá ph√≤ng C√¥ng t√°c sinh vi√™n v√† Thanh tra gi√°o d·ª•c ‚Äì T·∫ßng tr·ªát nh√† E ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n\n",
            "\n",
            "Context: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Question em mu·ªën ƒëƒÉng k√Ω h·ªçc ng√†nh 2?\n",
            "\n",
            "Answer: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Context: ch√†o em; anh vƒÉn A2 hi√™n t·∫°i ƒë√£ ƒë·∫ßy sƒ© s·ªë; em ch·ªù ƒë·ª£t 2 n·∫øu m·ªü th√™m nh√≥m em ƒëƒÉng k√Ω nha\n",
            "\n",
            "Question Em xin ch√†o ph√≤ng ƒê√†o t·∫°o, cho em h·ªèi: em m·ªõi h·ªçc ƒë·∫øn h·ªçc ph·∫ßn anh vƒÉn A1, em mu·ªën ƒëƒÉng k√Ω h·ªçc ti·∫øp h·ªçc ph·∫ßn anh vƒÉn A2 m√† em th·∫•y tr√™n m·∫°ng ch·ªâ c√≥ h·ªçc ph·∫ßn anh vƒÉn B1 th√¥i th√¨ em ph·∫£i l√†m sao? Em ch√¢n th√†nh c·∫£m ∆°n\n",
            "\n",
            "Answer: ch√†o em; anh vƒÉn A2 hi√™n t·∫°i ƒë√£ ƒë·∫ßy sƒ© s·ªë; em ch·ªù ƒë·ª£t 2 n·∫øu m·ªü th√™m nh√≥m em ƒëƒÉng k√Ω nha\n",
            "\n",
            "Context: Ch√†o em, em l√™n Ph√≤ng ƒë√†o t·∫°o g·∫∑p tr·ª±c ti·∫øp C√¥ Th√∫y nh√©. Tr√¢n tr·ªçng!\n",
            "\n",
            "Question em mu·ªën bi·∫øt c√°ch x·∫øp lo·∫°i t·ªët nghi·ªáp th√¨ l√†m sao?\n",
            "\n",
            "Answer: Ch√†o em, em l√™n Ph√≤ng ƒë√†o t·∫°o g·∫∑p tr·ª±c ti·∫øp\n",
            "\n",
            "Context: Li√™n h·ªá ph√≤ng c√¥ng t√°c sinh vi√™n v√† thanh tra gi√°o d·ª•c nha em.\n",
            "\n",
            "Question Cho em xin h·ªèi:em gi·ªù kh√¥ng nh·ªõ m·∫≠t kh·∫©u ƒëƒÉng nh·∫≠p c·∫ßn l·∫•y l·∫°i m·∫≠t kh·∫©u th√¨ l√†m sao ƒë∆∞·ª£c ·∫°?\n",
            "\n",
            "Answer: Li√™n h·ªá ph√≤ng c√¥ng t√°c sinh vi√™n v√† thanh tra gi√°o d·ª•c nha em\n",
            "\n",
            "Context: L·ªõp h·ªçc l√† nh·ªØng ng∆∞·ªùi h·ªçc tr√∫ng tuy·ªÉn c√πng kh√≥a tuy·ªÉn sinh, h·ªçc chung m·ªôt ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o s·∫Ω t·ªï ch·ª©c th√†nh m·ªôt ho·∫∑c nhi·ªÅu l·ªõp h·ªçc. L·ªõp h·ªçc ph·∫ßn l√† l·ªõp c·ªßa ng∆∞·ªùi h·ªçc c√πng ƒëƒÉng k√Ω m·ªôt h·ªçc ph·∫ßn, c√≥ c√πng th·ªùi kh√≥a bi·ªÉu c·ªßa h·ªçc ph·∫ßn trong c√πng m·ªôt h·ªçc k·ª≥. M·ªói l·ªõp h·ªçc ph·∫ßn ƒë∆∞·ª£c g√°n m·ªôt m√£ s·ªë ri√™ng. S·ªë l∆∞·ª£ng ng∆∞·ªùi h·ªçc c·ªßa m·ªôt l·ªõp h·ªçc ph·∫ßn ƒë∆∞·ª£c gi·ªõi h·∫°n b·ªüi s·ª©c ch·ª©a c·ªßa ph√≤ng h·ªçc ho·∫∑c ƒë∆∞·ª£ s·∫Øp x·∫øp theo c√°c y√™u c·∫ßu ri√™ng ƒë·∫∑c th√π c·ªßa h·ªçc ph·∫ßn. S·ªë l∆∞·ª£ng ng∆∞·ªùi h·ªçc t·ªëi thi·ªÉu cho m·ªói l·ªõp h·ªçc ph·∫ßn quy ƒë·ªãnh\n",
            "\n",
            "Question L·ªõp h·ªçc l√† g√¨?\n",
            "\n",
            "Answer: L·ªõp h·ªçc l√† nh·ªØng ng∆∞·ªùi h·ªçc tr√∫ng tuy·ªÉn c√πng kh√≥a tuy·ªÉn sinh, h·ªçc chung m·ªôt ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o s·∫Ω t·ªï ch·ª©c th√†nh m·ªôt ho·∫∑c nhi·ªÅu l·ªõp h·ªçc.\n",
            "\n",
            "Context: ch√†o em; hi·ªán t·∫°i ƒë√£ h·∫øt h·∫°n h·ªßy h·ªçc ph·∫ßn r·ªìi nh√© em\n",
            "\n",
            "Question V√†o ng√†y 3/7/2019, em th·ª±c hi·ªán ph·∫ßn ƒëƒÉng k√≠ k·ªπ nƒÉng m·ªÅm do tr∆∞·ªùng m·ªü ra. Nh∆∞ng e ƒë√£ ƒëƒÉng k√≠ nh·∫ßm ph·∫ßn k·ªπ nƒÉng ƒë√†m ph√°n c·ªßa ng√†nh kh√°c. Nay e k√≠nh mong tr∆∞·ªùng c√≥ th·ªÉ cho e h·ªßy h·ªçc ph·∫ßn ƒë√≥. Em ch√¢n th√†nh c·∫£m ∆°n ·∫°\n",
            "\n",
            "Answer: ch√†o em; hi·ªán t·∫°i ƒë√£ h·∫øt h·∫°n h·ªßy h·ªçc ph·∫ßn r·ªìi nh√© em\n",
            "\n",
            "Context: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Question em mu·ªën xin chuy·ªÉn ƒë·∫øn h·ªçc ·ªü Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng Th∆∞∆°ng Th√†nh ph·ªë H·ªì Ch√≠ Minh?\n",
            "\n",
            "Answer: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Context: Quy tr√¨nh ƒëƒÉng k√Ω h·ªçc ph·∫ßn: Ng∆∞·ªùi h·ªçc xem ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o trong t·ª´ng h·ªçc k·ª≥, danh s√°ch c√°c h·ªçc ph·∫ßn b·∫Øt bu·ªôc v√† t·ª± ch·ªçn, ƒëi·ªÅu ki·ªán ti√™n quy·∫øt ƒë·ªÉ ƒë∆∞·ª£c ƒëƒÉng k√Ω h·ªçc cho t·ª´ng h·ªçc ph·∫ßn t·∫°i c·ªïng th√¥ng tin sinh vi√™n. Trong m·ªói h·ªçc k·ª≥ ch√≠nh th∆∞·ªùng c√≥ hai ƒë·∫øn ba\n",
            "\n",
            "Question N·∫øu nh√≥m h·ªçc ph·∫ßn sinh vi√™n ƒë√£ k√Ω m√† b·ªã h·ªßy th√¨ sinh vi√™n xem th√¥ng tin ·ªü ƒë√¢u v√† ƒëƒÉng k√Ω nh∆∞ th·∫ø n√†o?\n",
            "\n",
            "Answer: Quy tr√¨nh ƒëƒÉng k√Ω h·ªçc ph·∫ßn: Ng∆∞·ªùi h·ªçc xem ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o trong t·ª´ng h·ªçc k·ª≥, danh s√°ch c√°c h·ªçc ph·∫ßn b·∫Øt bu·ªôc v√† t·ª± ch·ªçn, ƒëi·ªÅu ki·ªán ti√™n quy·∫øt ƒë·ªÉ ƒë∆∞·ª£c ƒëƒÉng k√Ω h·ªçc cho t·ª´ng h·ªçc ph·∫ßn t·∫°i c·ªïng th√¥ng tin sinh vi√™n.\n",
            "\n",
            "Context: Ch√†o em; hi·ªán t·∫°i M√¥n th√≠ nghi·ªám v·∫≠t l√Ω kh√¥ng c√≤n n·ªØa; em c√≥ th·ªÉ ƒëƒÉng k√Ω h·ªçc m√¥n V·∫≠t l√Ω ƒë·∫°i c∆∞∆°ng 3 ƒë·ªÉ thay th·∫ø nha em\n",
            "\n",
            "Question DaÃ£ em chaÃÄo th√¢ÃÄy c√¥ aÃ£. E laÃÄ sinh vi√™n khoaÃÅ 06. Do 1 s√¥ÃÅ sai soÃÅt n√™n m√¥n ThiÃÅ nghi√™Ã£m v√¢Ã£t lyÃÅ e ch∆∞a ƒëƒÉng kiÃÅ hoÃ£c ph√¢ÃÄn. DaÃ£ th√¢ÃÄy c√¥ coÃÅ th√™Ãâ cho e bi√™ÃÅt ƒë∆∞∆°Ã£c m√¥n hoÃ£c ph√¢ÃÄn t∆∞∆°ng ƒë∆∞∆°ng cuÃâa m√¥n naÃÄy kh√¥ng aÃ£. E caÃâm ∆°n aÃ£\n",
            "\n",
            "Answer: Ch√†o em; hi·ªán t·∫°i M√¥n th√≠ nghi·ªám v·∫≠t l√Ω kh√¥ng c√≤n n·ªØa; em c√≥ th·ªÉ ƒëƒÉng k√Ω h·ªçc m√¥n V·∫≠t l√Ω ƒë·∫°i c∆∞∆°ng 3 ƒë·ªÉ thay th·∫ø nha em\n",
            "\n",
            "Context: em li√™n h·ªá ph√≤ng C√¥ng t√°c sinh vi√™n v√† Thanh tra gi√°o d·ª•c ‚Äì T·∫ßng tr·ªát nh√† E ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n\n",
            "\n",
            "Question Em kh√¥ng bi·∫øt ch·ª©c nƒÉng n√†y c√≥ ƒëang ho·∫°t ƒë·ªông hay kh√¥ng. Nh∆∞ng em ƒë√£ g·ª≠i m·ªôt b√†i t∆∞∆°ng t·ª± cho ph√≤ng CTSV v√† TTGD nh∆∞ng kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi. N·∫øu n√≥ th·ª±c s·ª± l√† ƒëang ho·∫°t ƒë·ªông th√¨ em mong s·∫Ω nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi t·∫°i ƒë√¢y ·∫°\n",
            "\n",
            "Answer: em li√™n h·ªá ph√≤ng C√¥ng t√°c sinh vi√™n v√† Thanh tra gi√°o d·ª•c ‚Äì T·∫ßng tr·ªát nh√† E ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n\n",
            "\n",
            "Context: li√™n h·ªá Trung t√¢m GD Th·ªÉ ch·∫•t qu·ªëc ph√≤ng ƒë·ªÉ ƒë∆∞·ª£c h∆∞·ªõng d·∫´n\n",
            "\n",
            "Question th∆∞a th·∫ßy, c√¥ c√≥ th·ªÉ m·ªü th√™m gi√°o d·ª•c th·ªÉ ch·∫•t 2 b√≥ng chuy·ªÅn ƒë∆∞·ª£c kh√¥ng ·∫°, c√≥ r·∫•t nhi·ªÅu sinh vi√™n mu·ªën h·ªçc tr√™n fanpage ·∫°, m√πa ƒë√¥ng m√† m·ªü b∆°i th√¨ h∆°i l·∫°nh, mong nh√† tr∆∞·ªùng gi√∫p ƒë·ª° c√≥ th√™m l·ªõp.\n",
            "\n",
            "Answer: li√™n h·ªá Trung t√¢m GD Th·ªÉ ch·∫•t qu·ªëc ph√≤ng ƒë·ªÉ ƒë∆∞·ª£c h∆∞·ªõng d·∫´n\n",
            "\n",
            "Context: Em li√™n h·ªá ph√≤ng K·∫ø ho·∫°ch ‚Äì T√†i ch√≠nh ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£\n",
            "\n",
            "Question Em ƒë√£ ƒë√≥ng h·ªçc ph√≠ ng√†y 7 th√°ng 3, nh∆∞ng trang web b·∫£o 'n·ª£ h·ªçc ph√≠' (v√¨ h·∫°n ch√≥t n·ªôp h·ªçc ph√≠ l√† 8/3/2024).\n",
            "\n",
            "Answer: Em li√™n h·ªá ph√≤ng K·∫ø ho·∫°ch ‚Äì T√†i ch√≠nh ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£\n",
            "\n",
            "Context: ch√†o em; hi·ªán t·∫°i kh√¥ng ƒë∆∞·ª£c h·ªßy m√¥n h·ªçc n·ªØa nha em\n",
            "\n",
            "Question K√≠nh g·ª≠i ph√≤ng ƒë√†o t·∫°o. Em c√≥ ƒëƒÉng k√Ω m√¥n ‚Äú qu·∫£n tr·ªã chi·∫øn l∆∞·ª£c‚Äù nh∆∞ng v√¨ ƒë√≥ l√† m√¥n h·ªçc v∆∞·ª£t. N√™n em mong ph√≤ng ƒë√†o t·∫°o c√≥ th·ªÉ hu·ª∑ gi√∫p em m√¥n ƒë√≥ v·ªõi ·∫°. ƒê·ªÉ e c√≥ th·ªÉ ƒëƒÉng k√Ω m√¥n ‚ÄúGDQP3-AB‚Äú ·∫° . Em c·∫£m ∆°n ph√≤ng ƒë√†o t·∫°o\n",
            "\n",
            "Answer: ch√†o em; hi·ªán t·∫°i kh√¥ng ƒë∆∞·ª£c h·ªßy m√¥n h·ªçc n·ªØa nha em\n",
            "\n",
            "Context: T√≠n ch·ªâ h·ªçc ph√≠ l√† m·ªôt ƒë∆°n v·ªã d√πng ƒë·ªÉ l∆∞·ª£ng h√≥a chi ph√≠ c·ªßa c√°c ho·∫°t ƒë·ªông gi·∫£ng d·∫°y, h·ªçc t·∫≠p t√≠nh cho t·ª´ng h·ªçc ph·∫ßn. M·ª©c ti·ªÅn h·ªçc ph√≠ c·ªßa 01 t√≠n ch·ªâ h·ªçc ph√≠ do Hi·ªáu tr∆∞·ªüng quy ƒë·ªãnh cho t·ª´ng b·∫≠c ƒë√†o t·∫°o, h√¨nh th·ª©c ƒë√†o t·∫°o. H·ªçc ph√≠ t√≠nh theo m·ªói h·ªçc k·ª≥ m√† ng∆∞·ªùi h·ªçc theo h·ªçc t·∫°i HUFI. H·ªçc ph√≠ h·ªçc k·ª≥ ƒë∆∞·ª£c x√°c ƒë·ªãnh cƒÉn c·ª© v√†o s·ªë t√≠n ch·ªâ h·ªçc ph·∫ßn c·ªßa ng∆∞·ªùi ƒëƒÉng k√Ω trong th·ªùi kh√≥a bi·ªÉu h·ªçc k·ª≥. H·ªçc ph√≠ h·ªçc k·ª≥ ƒë∆∞·ª£c t√≠nh b·∫±ng t·ªïng c·ªßa m·ª©c h·ªçc ph√≠ l√Ω thuy·∫øt nh√¢n v·ªõi s·ªë t√≠n ch·ªâ l√Ω thuy·∫øt v√† m·ª©c h·ªçc ph√≠ th·ª±c h√†nh nh√¢n v·ªõi s·ªë t√≠n ch·ªâ th·ª±c h√†nh. H·ªçc ph√≠ c·ªßa c√°c h·ªçc ph·∫ßn ng∆∞·ªùi h·ªçc ƒë√£ ƒëƒÉng k√Ω ƒë∆∞·ª£c th·ªÉ hi·ªán tr√™n c·ªïng th√¥ng tin sinh vi√™n c·ªßa t·ª´ng ng∆∞·ªùi h·ªçc. Tr∆∞·ªùng h·ª£p c√≥ kh√≥ khƒÉn ƒë·ªôt ƒë·ªôt xu·∫•t sinh vi√™n ph·∫£i n·ªôp ƒë∆°n gia h·∫°n t·∫°i ph√≤ng C√¥ng t√°c sinh vi√™n v√† Thanh tra gi√°o d·ª•c.\n",
            "\n",
            "Question N·∫øu sinh vi√™n g·∫∑p kh√≥ kh·∫Øn ƒë·ªôt xu·∫•t kh√¥ng c√≥ kh·∫£ nƒÉng ƒë√≥ng h·ªçc ph√≠ th√¨ sinh vi√™n ph·∫£i l√†m g√¨?\n",
            "\n",
            "Answer: Ch∆∞a th·ªÉ t√¨m th·∫•y c√¢u tr·∫£ l·ªùi \n",
            "\n",
            "Context: Kh√≥a h·ªçc l√† th·ªùi gian thi·∫øt k·∫ø ƒë·ªÉ ng∆∞·ªùi h·ªçc ho√†n th√†nh m·ªôt ch∆∞∆°ng tr√¨nh. Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o li√™n th√¥ng cao ƒë·∫≥ng l√™n ƒë·∫°i h·ªçc h·ªá ch√≠nh quy c·∫•p b·∫±ng c·ª≠ nh√¢n c√≥ 3 h·ªçc k·ª≥ (1.5 nƒÉm) t·ªëi ƒëa 6 h·ªçc k·ª≥ (3 nƒÉm). Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o li√™n th√¥ng cao ƒë·∫≥ng l√™n ƒë·∫°i h·ªçc h·ªá\n",
            "\n",
            "Question Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o cao ƒë·∫≥ng l√™n ƒë·∫°i h·ªçc ch√≠nh quy c·∫•p b·∫±ng k·ªπ s∆∞ h·ªçc m·∫•y nƒÉm?\n",
            "\n",
            "Answer: Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o li√™n th√¥ng cao ƒë·∫≥ng l√™n ƒë·∫°i h·ªçc h·ªá\n",
            "\n",
            "Context: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Question h·ªçc xong nh·∫≠n b·∫±ng t·ªët nghi·ªáp ·ªü ƒë√¢u?\n",
            "\n",
            "Answer: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Context: Ch√†o em, em l√™n Ph√≤ng ƒë√†o t·∫°o g·∫∑p tr·ª±c ti·∫øp C√¥ Th√∫y nh√©. Tr√¢n tr·ªçng!\n",
            "\n",
            "Question em mu·ªën h·ªèi k·∫øt qu·∫£ x√©t t·ªët nghi·ªáp th√¨ h·ªèi ·ªü ƒë√¢u\n",
            "\n",
            "Answer: Ch√†o em, em l√™n Ph√≤ng ƒë√†o t·∫°o g·∫∑p tr·ª±c ti·∫øp\n",
            "\n",
            "Context: em mang t·ªù gi·∫•y ho√£n thi li√™n h·ªá Trung t√¢m kh·∫£o th√≠ v√† ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng; ki·ªÉm tra ghi ƒëi·ªÉm v√† ƒë∆∞a xu·ªëng ph√≤ng ƒë√†o t·∫°o ƒë·ªÉ ƒë∆∞·ª£c nh·∫≠p ƒëi·ªÉm. em li√™n h·ªá Trung t√¢m qu·∫£n l√Ω ch·∫•t l∆∞·ª£ng ƒë·ªÉ h·ªèi ƒëi·ªÉm.\n",
            "\n",
            "Question e l√†m m·∫•t t·ªù gi·∫•y ho√£n thi r·ªìi. gi·ªù ph·∫£i l√†m sao ·∫°\n",
            "\n",
            "Answer: em li√™n h·ªá Trung t√¢m qu·∫£n l√Ω ch·∫•t l∆∞·ª£ng ƒë·ªÉ h·ªèi ƒëi·ªÉm.\n",
            "\n",
            "Context: H·ªçc ph·∫ßn A l√† ti√™n quy·∫øt c·ªßa h·ªçc ph·∫ßn B, ƒëi·ªÅu ki√™n b·∫Øt bu·ªôc ƒë·ªÉ ƒëƒÉng k√Ω h·ªçc h·ªçc ph·∫ßn B l√† ng∆∞·ªùi h·ªçc ƒë√£ h·ªçc ho√†n t·∫•t h·ªçc ph·∫ßn A v√† k·∫øt ph·∫£i ƒë·∫°t y√™u c·∫ßu. H·ªçc ph·∫ßn A l√† h·ªçc ph·∫ßn tr∆∞·ªõc ƒë·ªëi v·ªõi h·ªçc ph·∫ßn B n·∫øu nh∆∞ ng∆∞·ªùi h·ªçc ƒë√£ ƒëƒÉng k√Ω h·ªçc v√† c√≥ ƒëi·ªÉm thi h·ªçc ph·∫ßn A (k·ªÉ c·∫£ ƒëi·ªÉm thi ch∆∞a ƒë·∫°t), khi ·∫•y ng∆∞·ªùi h·ªçc ƒë∆∞·ª£c ph√©p ƒëƒÉng k√Ω h·ªçc ph·∫ßn B v√†o c√°c h·ªçc k·ª≥ sau. H·ªçc ph·∫ßn B l√† song h√†nh ƒë·ªëi v·ªõi h·ªçc ph·∫ßn A v·ªõi ƒëi·ªÅu ki·ªán b·∫Øt bu·ªôc ƒë·ªÉ h·ªçc h·ªçc ph·∫ßn B th√¨ ng∆∞·ªùi h·ªçc ƒë√£ ƒëƒÉng k√Ω h·ªçc ph·∫ßn A. Ng∆∞·ªùi h·ªçc ƒë∆∞·ª£c ph√©p ƒëƒÉng k√Ω h·ªçc ph·∫ßn B v√†o c√πng h·ªçc k·ª≥ v·ªõi h·ªçc ph·∫ßn A.\n",
            "\n",
            "Question H·ªçc ph·∫ßn A ƒë∆∞·ª£c g·ªçi l√† h·ªçc ph·∫ßn ti√™n quy·∫øt v·ªõi h·ªçc ph·∫ßn B th√¨ khi ch∆∞a ƒë·∫°t h·ªçc ph·∫ßn A th√¨ c√≥ ƒëƒÉng k√Ω h·ªçc ph·∫ßn B ƒë∆∞·ª£c kh√¥ng?\n",
            "\n",
            "Answer: H·ªçc ph·∫ßn A l√† ti√™n quy·∫øt c·ªßa h·ªçc ph·∫ßn B, ƒëi·ªÅu ki√™n b·∫Øt bu·ªôc ƒë·ªÉ ƒëƒÉng k√Ω h·ªçc h·ªçc ph·∫ßn B l√† ng∆∞·ªùi h·ªçc ƒë√£ h·ªçc ho√†n t·∫•t h·ªçc ph·∫ßn A v√† k·∫øt ph·∫£i ƒë·∫°t y√™u c·∫ßu.\n",
            "\n",
            "Context: ch√†o em; em mu·ªën ƒë·ªïi t·ª´ ng√†nh g√¨ qua ng√†nh g√¨ em\n",
            "\n",
            "Question D·∫° cho em h·ªèi l√† em mu·ªën ƒë·ªïi ng√†nh nh∆∞ng kh√¥ng c√≤n gi·∫•y b√°o tr√∫ng tuy·ªÉn th√¨ em c√≥ ƒë∆∞·ª£c ch·∫•p nh·∫≠n kh√¥ng ·∫°.\n",
            "\n",
            "Answer: ch√†o em; em mu·ªën ƒë·ªïi t·ª´ ng√†nh g√¨ qua ng√†nh g√¨ em\n",
            "\n",
            "Context: li√™n h·ªá ph√≤ng c√¥ng t√°c sinh vi√™n v√† thanh tra gi√°o d·ª•c h·ªèi em nh√©.\n",
            "\n",
            "Question Cho em h·ªèi tr∆∞·ªùng c√≥ gia h·∫°n h·ªçc ph√≠ ko\n",
            "\n",
            "Answer: li√™n h·ªá ph√≤ng c√¥ng t√°c sinh vi√™n v√† thanh tra gi√°o d·ª•c h·ªèi em nh√©.\n",
            "\n",
            "Context: ch√†o em; c√¥ ki·ªÉm tra th·∫ßy em kh√¥ng c√≥ ƒëi·ªÉm ti·ªÉu lu·∫≠n; c√≤n ƒëi·ªÉm cu·ªëi k·ª≥ c·∫£ l·ªõp ch∆∞a c√≥ em nh√©\n",
            "\n",
            "Question D·∫° th·∫ßy c√¥ ki·ªÉm tra gi√∫p em v·ªõi ·∫°, m√¥n kƒ© nƒÉng h·ªçc t·∫≠p hi·ªáu qu·∫£ h·ªçc h√® v·ª´a r·ªìi, em c√≥ ƒëi thi, khi n·ªôp b√†i c≈©ng c√≥ k√≠ t√™n nh∆∞ng t·∫°i sao ƒëi·ªÉm c·ªßa e l·∫°i l√† 0 ƒëi·ªÉm ·∫°, th·∫ßy c√¥ ki·ªÉm tra gi√∫p em v·ªõi ·∫°\n",
            "\n",
            "Answer: ch√†o em; c√¥ ki·ªÉm tra th·∫ßy em kh√¥ng c√≥ ƒëi·ªÉm ti·ªÉu lu·∫≠n; c√≤n ƒëi·ªÉm cu·ªëi k·ª≥ c·∫£ l·ªõp ch∆∞a c√≥ em nh√©\n",
            "\n",
            "Context: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Question em hi·ªán t·∫°i l√† sinh vi√™n tr∆∞·ªùng kh√°c, em mu·ªën xin chuy·ªÉn ƒë·∫øn h·ªçc ·ªü HUIT?\n",
            "\n",
            "Answer: Ph√≤ng ƒê√†o t·∫°o ‚Äì t·∫ßng tr·ªát nh√† C\n",
            "\n",
            "Context: theo ti·∫øn ƒë·ªô th√¨ kho·∫£ng 3/6 ƒë·∫øn 23/6 em nh√© em ƒë·ª£i th√¥ng b√°o c·ª• th·ªÉ v·ªÅ l·ªãch thi c·ªßa nh√† tr∆∞·ªùng nha em.\n",
            "\n",
            "Question Cho em hoÃâi liÃ£ch thi HK2 cuÃâa khoa c√¥ng ngh√™Ã£ th∆∞Ã£c ph√¢Ãâm trong ƒë∆°Ã£t 2 bƒÉÃÅt ƒë√¢ÃÄu t∆∞ÃÄ ngaÃÄy naÃÄo aÃ£?\n",
            "\n",
            "Answer: theo ti·∫øn ƒë·ªô th√¨ kho·∫£ng 3/6 ƒë·∫øn 23/6 em nh√© em ƒë·ª£i th√¥ng b√°o c·ª• th·ªÉ v·ªÅ l·ªãch thi c·ªßa nh√† tr∆∞·ªùng nha em.\n",
            "\n",
            "Validation F1 Score: 75.67%\n",
            "Validation Exact Match Score: 64.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ƒê∆∞a model v·ªÅ thi·∫øt b·ªã (CPU ho·∫∑c GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc_MV4e5wt9s",
        "outputId": "71162b61-9790-49bd-d81a-ee5d8e31455c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForQuestionAnswering(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a17f02eaf56c41da83292ffe2c2ff980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04ab845524af4f3c98ad99df54e61127",
              "IPY_MODEL_acea7e731c36455c9e6426df789817fd",
              "IPY_MODEL_0005666ebab14e87a406115427dbbc88"
            ],
            "layout": "IPY_MODEL_0705bd75a7024040923d900149b4fc10"
          }
        },
        "04ab845524af4f3c98ad99df54e61127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9eacaba2fa3420389b9c461b326dd87",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2df56c8b324c470e967e2e3285fdc3e4",
            "value": "Map:‚Äá100%"
          }
        },
        "acea7e731c36455c9e6426df789817fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb5655b4d0ca4d03af16c7b1d3b28f18",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbe971ebd3ce4a36b1be233f18fd3729",
            "value": 500
          }
        },
        "0005666ebab14e87a406115427dbbc88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d74f61959a5a434ebe06638f35c4a31b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b3c5d7da39db4b05a9bbd6b61030a620",
            "value": "‚Äá500/500‚Äá[00:00&lt;00:00,‚Äá2889.96‚Äáexamples/s]"
          }
        },
        "0705bd75a7024040923d900149b4fc10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9eacaba2fa3420389b9c461b326dd87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2df56c8b324c470e967e2e3285fdc3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb5655b4d0ca4d03af16c7b1d3b28f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbe971ebd3ce4a36b1be233f18fd3729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d74f61959a5a434ebe06638f35c4a31b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c5d7da39db4b05a9bbd6b61030a620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c99b6429f4ef4e8bbc0d9e132ef904ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4aac80206614c4f82f5f5d010b1b9ec",
              "IPY_MODEL_a3c4b3ebea24416ebea0c5bf15fcd970",
              "IPY_MODEL_5044ebf3aef0419db56150381f646378"
            ],
            "layout": "IPY_MODEL_2e2455995add4eeda941ae66cfdcacae"
          }
        },
        "f4aac80206614c4f82f5f5d010b1b9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_256c005a8400411db943baec1c879004",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a52739ba7bfc43a3b23729dd47c8cb5e",
            "value": "Map:‚Äá100%"
          }
        },
        "a3c4b3ebea24416ebea0c5bf15fcd970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_124f71fcac64472db35b72abfd78cca1",
            "max": 56,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_481d3d5bce1b4696923571f53fa1caa1",
            "value": 56
          }
        },
        "5044ebf3aef0419db56150381f646378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804f265d192f43d583e1b9bb3f5efab4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1d5a40fa12274020ab9f1421a10cf642",
            "value": "‚Äá56/56‚Äá[00:00&lt;00:00,‚Äá1153.17‚Äáexamples/s]"
          }
        },
        "2e2455995add4eeda941ae66cfdcacae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256c005a8400411db943baec1c879004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52739ba7bfc43a3b23729dd47c8cb5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "124f71fcac64472db35b72abfd78cca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "481d3d5bce1b4696923571f53fa1caa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "804f265d192f43d583e1b9bb3f5efab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5a40fa12274020ab9f1421a10cf642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}